[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analyzing Canadian Demographic and Housing Data",
    "section": "",
    "text": "Preface\nThis book is intended for people interested in learning how to access, process, analyze, and visualize Canadian demographic, economic, and housing data using R. The target audience we have in mind ranges from individuals interested in understanding their environment through data, community activists and community groups interested in introducing data-based approached into their work, journalists who want to report on data in their stories or aim to incorporate their own descriptive data analysis, non-profits or people involved in policy who are looking for data-based answers to their questions.\nThe most important prerequisite is a keen interest in using data to help understand how housing and demographics shape cities and rural areas in Canada, and a willingness to learn. Prior knowledge of R is not necessary, but may be beneficial.\nCanada has high quality demographic, economic and housing data. While significant data gaps exist, the available data often remains under-utilized in policy and planning analyses. Moreover, many analyses that do come out go quickly out of date and can’t easily be updated because they rely on non-reproducible and non-adaptable workflows.\nIn this book we will maintain a strong emphasis on reproducible and adaptable work flows to ensure the analysis is transparent, can easily be updated as new data becomes available, and can be tweaked or adapted to address related questions.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#under-construction",
    "href": "index.html#under-construction",
    "title": "Analyzing Canadian Demographic and Housing Data",
    "section": "Under construction",
    "text": "Under construction\nAt this point this book is more aspirational than reality, It will take time to build this out so that it can be used as a standalone resource to cover basic data analysis and visualization workflows in R, as well as be a comprehensive introduction into Canadian data sources.\nWe are planning to add to this book as we find time and come across good examples that are simple enough to slowly build skills, as well as interesting enough to be engaging and motivating to the reader. Until that point the order of sections will change as we add new material, and we will come back and revise existing sections as we receive feedback from readers, which we encourage and is ideally submitted as a GitHub issue.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#project-based-approach",
    "href": "index.html#project-based-approach",
    "title": "Analyzing Canadian Demographic and Housing Data",
    "section": "Project based approach",
    "text": "Project based approach\nThis book will take a project based approach to teach through examples, with one project per section. Each project will be loosely broken up into four parts.\n\nFormulating the question. What is the question we are interested in? Asking a clear question will help focus our efforts and ensure that we don’t aimlessly trawl through data.\nIdentifying possible data sources. Here we try to identify data sources that can speak to our question. We will also take the time to read up on definitions and background concepts to better understand the data and prepare us for data analysis, and understand how well the concepts in the data match our original question from step 1.\nData acquisition. In this step we will import the data into our current working session. This could be as simple as an API call, or more complicated like scraping a table from the web, or involve even more complex techniques to acquire the data.\nData preparation. In this step we will reshape and filter the data to prepare it for analysis.\nAnalysis. This step could be as simple as computing percentages or even doing nothing, if the quantities we are interested in already come with the dataset, if our question can be answered by a simple descriptive analysis. In other cases, when our question is more complex, this step may be much more involved. The book will try to slowly build up analysis skills along the way, with increasing complexity of questions and required analysis.\nVisualization. The final step in the analysis process is to visualize and communicate the results. In some cases this can be done via a table or a couple of paragraphs of text explaining the results, but in most cases it is useful to produce graphs or maps or even interactive visualizations to effectively communicate the results.\nInterpretation. What’s left to wrap this up is to interpret the results. How does this answer our question, where does it fall short. What does this mean in the real-world context? What new questions emerge from this?\n\nWhile we won’t always follow this step by step process to the letter, it will be our guiding principle throughout the book. Sometimes things won’t go so clean, where after the visualization step we notice that something looks off or is unexpected, and we may jump back up a couple of steps and add more data and redo parts of the analysis to better understand our data and how it speaks to our initial questions. We might even come to understand that our initial question was not helpful or was ill-posed, and we will come back to refine it.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Analyzing Canadian Demographic and Housing Data",
    "section": "Goals",
    "text": "Goals\nBy taking this approach we have several goals in mind:\n\nStay motivated by using real world Canada-focused and (hopefully) interesting examples.\nTeach basic data literacy, appreciate definitions and quirks in the data.\nExpose the world of Canadian data and make it more accessible.\nLearn how data can be interpreted in different ways, and data and analysis is not necessarily “neutral”.\nLearn how to effectively communicate results.\nLearn how to adapt and leverage off of previous work to answer new questions.\nLearn how to reproduce and critique data analysis.\nBuild a community around Canadian data, where people interested in similar questions, or people using the same data, can learn from each other.\nRaise the level of understanding of Canadian data and data analysis so we are better equipped to tackle the problems Canada faces.\n\nThis is setting a very high goal for this book, and we are not sure we can achieve all of this. But we will try our best to be accessible and interesting as possible.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#why-use-r",
    "href": "index.html#why-use-r",
    "title": "Analyzing Canadian Demographic and Housing Data",
    "section": "Why use R?",
    "text": "Why use R?\nMost people reading this book will not have used R before, or only used it peripherally, maybe during a college course many years in the past. Instead, readers may be familiar with working through housing and demographic data in Excel or similar tools. Or making maps in QGIS or similar tools when dealing with spatial data. And the type of analysis outlined above that this book will teach can in general terms be accomplished using these tools.\nBut where tools like spreadsheets and desktop GIS fall short is in another important focus of this book: transparency, reproducibility, and adaptability.\nAn analysis in a spreadsheet or desktop GIS typically involves a lot of manual steps, the work is not reproducible without repeating these steps. We can’t easily inspect how the result was derived, the analysis lacks transparency. When we just compute a ratio or percentage this may not be so bad, but trying to understand how a more complex analysis was done in a spreadsheet easily turns into a nightmare. Analysis that involves a lot of manual steps is not auditable without putting in the work to repeat those manual steps.\nBut why does this matter? It’s always been this way, some experts produce analysis and produce a glossy paper to present the results. One can argue if this was an adequate modus operandi in the past, but we feel strongly that it’s not in today’s world. The lines between experts and non-experts has become blurred, and the value we place on lived experience has increased relative to more formal expertise. We argue this places different demands on policy-relevant analysis, it needs to be open and transparent, in principle anyone should be able to understand how the analysis was done and the conclusions were reached. That’s where reproducibility and transparency come in. And it also requires bringing up data analysis skills in the broader population, so that the ability to reproduce and critique an analysis in principle can be realized in practice.\nThe remaining reason for using R, adaptability, has also become increasingly important. The amount of data available to us has increased tremendously, but our collective ability to analyse data and extract information has not kept up. Doing analysis in R allows us to efficiently reuse previous analysis to perform a similar one. Or to build on previous analysis to deepen it. Which turbocharges our ability to do analysis, covering more ground and going deeper.\nR is not the only framework to do this in, there are other options like python or julia. But we believe that R is best suited for people transitioning into this space, and we can rely on an existing ecosystem of packages to access and process Canadian data. People already proficient in python will have no problem translating what we do into their preferred framework, or dynamically switch back and forth between R, python or whatever other tools they prefer as needed and convenient.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#building-a-canadian-data-community",
    "href": "index.html#building-a-canadian-data-community",
    "title": "Analyzing Canadian Demographic and Housing Data",
    "section": "Building a Canadian data community",
    "text": "Building a Canadian data community\nWhich brings us to our most ambitious goal, to help create a community around Canadian data analysis. When analysis is transparent, reproducible and adaptable people can piggy-back of each other’s work, reusing parts of analysis others have done and building and improving upon it. Or Critiquing and correcting analysis, or taking it toward a different direction. A community that grows in their understanding of data, and a community using a shared set of tools to access and process Canadian data, enabling discussions to move forward instead of in circles. A community that builds up expertise from the bottom up.\nThe book tries to address both of these requirements for building a Canadian data community, a principled approach to data and data analysis, while introducing R as a common framework to work in hoping that the reader will come away with\n\nbetter data literacy skills to understand and critique data analysis,\ntechnical skills to reproduce and perform their own data analysis, and\na common tool set for acquiring, processing and analyzing Canadian data that facilitates collaborative practices.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Introduction\n",
    "section": "",
    "text": "1.1 A hypothetical example\nIn this section we give a taste of what’s to come. Some of the concepts introduced in the preface may be too abstract to picture for people just starting out in this space. People probably grasp the importance of having a principled approach to data analysis, from formulating a question all the way to sharing results. But why so much emphasis on reproducibility and adaptability? And do we really need to learn a new framework like R for this?\nThis is best understood by walking through a simple example of what analysis of Canadian data in R, and a Canadian data community might look like. We won’t explain all steps in full detail here, this is to serve to illustrate the concepts talked above in the preface and give the reader a taste of what’s to come.\nIf you don’t understand all the code now, don’t worry, that’s part of the point of this book. We will work out and explain these examples in detail in the first chapter of the book. What’s important right now is to illustrate the principle of reproducible and adaptable code, and how this can function to foster a community of Canadian data analysis. And to note how little code is needed to make this work.\nIf the code becomes a bit overwhelming, it’s also ok to just collapse individual code blocks for now, or all code blocks using the “&lt;/&gt;Code” dropdown menu at the top right of this page, and just follow along without it.\nImagine Amy, a Toronto-based social services worker looking to pilot a community intervention targeted at children in low income. She is in the process of putting together a proposal describing her intervention and is trying to locate a good neighbourhood for her pilot and make a compelling case to possible funders.\nAmy knows that census data has a good geographic breakdown of children in poverty, but the latest available data is from 2016, using 2015 income data. CRA tax data is available up to 2019, but also has information on families in low income, but nothing directly on children in the standard release tables at fine geographies. As a first step she settles on census data, with the goal to re-run the analysis once the 2021 data comes out later in the year.\nShe refers to the Census Dictionary to understand the various low income measures, and uses CensusMapper’s interactive map that allows to explore these concepts. She would have liked to use the Market Based Measure, but due to data availability she settles for LICO-AT.\nShe sets up a new Notebook and loads in the R libraries that she will need for this, ggplot2 for graphing and cancensus for ingesting the data.\nCodelibrary(cancensus)\nlibrary(ggplot2)\nNext she pull in the data. the CensusMapper API GUI tool helps her locate the StatCan geographic identifier for Toronto, (3520005), and the internal CensusMapper vector for the percentage of children in LICO-AT (v_CA16_2573).\nCodelico_yyz &lt;- get_census(\"CA16\",regions=list(CSD=\"3520005\"), vectors=c(lico=\"v_CA16_2573\"),\n                        level=\"CT\",geo_format=\"sf\")\nHere Amy specified that she wants data for the 2016 Canadian census (“CA16”), the region and vectors, at the census tract (“CT”) level, with geographies as well as the low income data.\nNow that she has the data at her finger tips her first step is to make a map. For that she needs to tell ggplot is what variable to use as fill colour, and maybe give it a nicer colour scale and some labels to explain what the map is about.\nCodeggplot(lico_yyz, aes(fill=(lico/100))) +\n  geom_sf() +\n  scale_fill_viridis_c(labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"Children in low income (LICO-AT)\",\n       fill=\"Share\",\n       caption=\"StatCan census 2016\")\nBased on this she locates a couple of good candidate neighbourhoods for her pilot and sends the map in a email to her colleague Peter to get input on which neighbourhood might be best suited.\nPeter has some good feedback for Amy, but also gets an idea to try and set up something similar in Vancouver. Peter asks Amy if she can share the code, and Amy sends along the above code snippets. Peter looks up the geographic identifier for Vancouver and subs that in instead of Toronto’s.\nCodelico_yvr &lt;- get_census(\"CA16\",regions=list(CSD=\"5915022\"), vectors=c(lico=\"v_CA16_2573\"),\n                        level=\"CT\",geo_format=\"sf\")\n\nggplot(lico_yvr, aes(fill=(lico/100))) +\n  geom_sf() +\n  scale_fill_viridis_c(labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"Children in low income (LICO-AT)\",\n       fill=\"Share\",\n       caption=\"StatCan census 2016\")\nEasy peasy, thanks to Amy’s previous work. Peter takes the map to his friend Yuko and asks her for advice where a community-based intervention for low-income children might make sense in Calgary. Yuko asks for the code from Peter to take a closer look herself.\nYuko is interested in a finer geographic breakdown, so she swaps our the geographic level from census tracts to dissemination areas.\nCodelico_yvr_da &lt;- get_census(\"CA16\",regions=list(CSD=\"5915022\"), vectors=c(lico=\"v_CA16_2573\"),\n                        level=\"DA\",geo_format=\"sf\")\n\nggplot(lico_yvr_da, aes(fill=(lico/100))) +\n  geom_sf() +\n  scale_fill_viridis_c(labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"Children in low income (LICO-AT)\",\n       fill=\"Share\",\n       caption=\"StatCan census 2016\")\nBut then Yuko pauses to think that maybe looking at share of the low income population is not the right metric. She decides to query the number of children in low income (vector “v_CA16_2558”) and prepare the data for a dot-density map.\nCode# remotes::install_github(\"mountainmath/dotdensity\")\nlibrary(dotdensity)\n\nlico_dots_yvr &lt;- get_census(\"CA16\",regions=list(CSD=\"5915022\"),geo_format=\"sf\",\n                            vectors=c(lico=\"v_CA16_2558\"), level=\"DA\") |&gt;\n  compute_dots(\"lico\")\nyvr_city &lt;- get_census(\"CA16\",regions=list(CSD=\"5915022\"),geo_format=\"sf\")\n\nggplot(lico_dots_yvr) +\n  geom_sf(data = yvr_city) +\n  geom_sf(colour=\"brown\",alpha=0.1) +\n  coord_sf(datum=NA) +\n  labs(title=\"Children in low income (LICO-AT)\",\n       fill=\"Share\",\n       caption=\"StatCan census 2016\")\nThat paints a somewhat different picture, and Yuko feels this is much better suited to pinpoint where to best stage a community intervention. She lets Peter and Amy know and emails them her modifications to the code.\nMeanwhile, Yuko’s Vancouver friend Stephanie is looking specifically at children below the age of 6 in low income, and wants to understand how the geographic distribution of low income children has changed over time. Comparing census data through time can be tricky because census geographies change, but this problem has been completely solved via the tongfen R package. Looking at Yuko’s work she thinks it might be best to look at both, the change in share of children in low income as well as the change in absolute number.\nCodelibrary(tongfen)\nmeta &lt;- meta_for_ca_census_vectors(c(total_2006=\"v_CA06_1982\",lico_share_2006=\"v_CA06_1984\",\n                                     lico_2016=\"v_CA16_2561\",lico_share_2016=\"v_CA16_2576\"))\n\nlico_data &lt;- get_tongfen_ca_census(regions=list(CSD=\"5915022\"),meta,level=\"CT\") |&gt;\n  mutate(lico_2006=total_2006*lico_share_2006/100) |&gt;\n  mutate(`Absolute change`=lico_2016-lico_2006,\n         `Percentage point change`=lico_share_2016-lico_share_2006)\nArmed with this data Stephanie can plot the absolute and percentage point change in children below 6 in low income.\nCodeggplot(lico_data,aes(fill=`Absolute change`)) +\n  geom_sf() +\n  scale_fill_gradient2() +\n  coord_sf(datum=NA) +\n  labs(title=\"Change in number of children under 6 in low income\",\n       caption=\"StatCan Census 2006, 2016\")\nCodeggplot(lico_data,aes(fill=`Percentage point change`/100)) +\n  geom_sf() +\n  scale_fill_gradient2(labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"Change in share of children under 6 in low income\",\n       fill=\"Percentage\\npoint change\",\n       caption=\"StatCan Census 2006, 2016\")\nStephanie shares her results with Amy in Toronto in case there are components of Amy’s pilot specifically targeting children below 6 in low income.\nMeanwhile Amy has been trying to understand more broadly how the share of low income children has evolved since the 2016 census (using 2015 income data) at the metropolitan level over longer time spans, so she looks through the StatCan socioeconomic tables and settles on table 11-10-0135, which also allows her to compare various low income concepts.\nCodelibrary(cansim)\nmbm_timeline &lt;- get_cansim(\"11-10-0135\") |&gt;\n  filter(`Persons in low income`==\"Persons under 18 years\",\n         GEO==\"Toronto, Ontario\",\n         Statistics==\"Percentage of persons in low income\")\n\nggplot(mbm_timeline,aes(x=Date,y=val_norm,colour=`Low income lines`)) +\n  geom_point(shape=21) +\n  geom_line() +\n  scale_y_continuous(labels=scales::percent) +\n  labs(title=\"Children in low income in Metro Toronto\",\n       y=\"Share of children in low income\",\n       x=NULL,\n       caption=\"StatCan Table 11-10-0135\")\nShe notes that there has been a substantial overall drop in children in low income since 2015 across all measures, which is excellent news. She considers pushing off her pilot project until after the 2021 census data comes out to first understand if the geographic patterns have changed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#what-you-will-learn-in-this-book",
    "href": "intro.html#what-you-will-learn-in-this-book",
    "title": "\n1  Introduction\n",
    "section": "\n1.2 What you will learn in this book",
    "text": "1.2 What you will learn in this book\nLooking at R code for the first time can be intimidating. If the code looks opaque right now, there is no need to worry. It will be explained in detail in the first chapter and is very much part of the rationale for writing this book. If decisions around what low income metric to pick, or why tongfen is needed to compare census data through time are not clear, again, that will be explained in this book in detail and expanding understanding of data and data analysis is the other big rationale for this book.\nReaders will learn how to reproduce analysis, how to critique analysis, and adapt it for their own purposes. And readers will learn how to conduct their own analysis in the Canadian context, based on questions and use cases relevant to them.\nHopefully the above hypothetical scenario have explained how the adaptability of the R code has made life much easier for several of the subsequent analysis steps, and how little code was needed to gain some insights and communicate results.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro/getting_started.html",
    "href": "intro/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Before we dive into data projections we want to give a quick overview over R, RStudio, tidyverse and the main data acquisition and processing packages for Canadian data that we will use.\nStatistics Canada produces a lot of high quality demographic and economic data for Canada. CMHC complements this with housing data, and municipalities across Canada often provide relevant data through their Open Data portals.",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "intro/intro_to_r.html",
    "href": "intro/intro_to_r.html",
    "title": "\n2  R, RStudio, and the tidyverse\n",
    "section": "",
    "text": "2.1 R and RStudio\nStatistics Canada produces a lot of high quality demographic and economic data for Canada. CMHC complements this with housing data, and municipalities across Canada often provide relevant data through their Open Data portals.\nWe will be working in R and the RStudio IDE, although using a different editor like Visual Studio Code works just as well, especially if you are already familiar with it. Within R we will be operating within the tidyverse framework, a group of R packages that work well together and allow for intuitive operations on data via pipes.\nWhile an introduction to R is part of the goal of this book, an we will slowly build up skills as we go, we not give a systematic introduction but rather build up skills slowly as we work on concrete examples. It may be beneficial to supplement this with a more principled introduction to R and the tidyverse.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R, RStudio, and the tidyverse</span>"
    ]
  },
  {
    "objectID": "intro/intro_to_r.html#packages",
    "href": "intro/intro_to_r.html#packages",
    "title": "\n2  R, RStudio, and the tidyverse\n",
    "section": "\n2.2 Packages",
    "text": "2.2 Packages\nPackages are bundled sets of functionality that expand base R. We install or upgrade packages with the install.packages`. For example, to install the tidyverse framework we type\n\nCodeinstall.packages(\"tidyverse\")\n\n\ninto the R console. This will install or upgrade the package and required dependencies. To make the functionality, for example the tibble function from the tibble package that is part of tidyverse, available to use we can then either access functions from the package using the :: namespace selector tibble::tibble() or first load the tibble or tidyverse package via library(tidyverse) that makes the tibble() function available without having to use the namespace selector.\nAdditionally, we will need a number of packages that handle data acquisition and processing for Canadian data.\n\nCodeinstall.packages(c(\"cancensus\",\"cansim\",\"cmhc\",\"tongfen\"))",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R, RStudio, and the tidyverse</span>"
    ]
  },
  {
    "objectID": "intro/intro_to_r.html#basic-data-manipulation-patterns",
    "href": "intro/intro_to_r.html#basic-data-manipulation-patterns",
    "title": "\n2  R, RStudio, and the tidyverse\n",
    "section": "\n2.3 Basic data manipulation patterns",
    "text": "2.3 Basic data manipulation patterns\nThere are several basic data manipulation patterns that we will use throughout, and we want to give a quick overview using the Palmer Penguins dataset from the palmerpenguins package.\n\nCodeinstall.packages(\"palmerpenguins\") # install the package if needed\n\n\nWe will at times require additional packages like this to accomplish specialized tasks, installing packages in R is generally a simple and pain-free procedure.\n\nCode# install.packages(\"palmerpenguins\") # install the package if needed\nlibrary(palmerpenguins)\n\n\nNow we have all the functionality of the palmerpenguins package available.\n\n2.3.1 Exploring the data\nWith the palmerpenguins package comes the penguins dataset, we can expect the first few rows using the head() function which displays the first few rows.\n\nCodehead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;int&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n4 Adelie  Torgersen           NA            NA            NA      NA &lt;NA&gt;   2007\n5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n6 Adelie  Torgersen           39.3          20.6         190    3650 male   2007\n# … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g\n\n\nThe str() function offers another convenient way to get an overview over the data.\n\nCodestr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nWe can also type View(penguins) into the console to view the dataset in a spreadsheet form.\n\n2.3.2 Basic data manipulation\nTo manipulate and visualize the data we load the tidyverse package.\n\nCodelibrary(tidyverse)\n\n\nWe will explore some common data manipulation and visualization workflows.\n\n2.3.2.1 Count groups\nTo see how many rows there are for each species we ‘pipe’ the penguins dataset into the count() verb. Pipes are how we can stepwise transform data, the pipe operator is given by %&gt;% within the tidyverse framework and now also available natively in base R via |&gt;. These two function (almost) the same way, and we will use both in this book.\n\nCodepenguins |&gt; count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nThis gives us the count of each species in the dataset, the pipe |&gt; inserts the left hand side as the first argument in the count() function. We could have equivalently written this without the pipe operator as count(penguins,species).\n\n2.3.2.2 Group and summarize\nThe usefulness of the pipe operator becomes clear when we chain several data transformations. If we want to know the mean bill length by species, we group by species and summarize the data.\n\nCodepenguins |&gt; \n  group_by(species) |&gt;\n  summarize(bill_length_mm=mean(bill_length_mm, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  species   bill_length_mm\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Adelie              38.8\n2 Chinstrap           48.8\n3 Gentoo              47.5\n\n\nHere we explicitly specify how missing values should be treated when summarizing, na.rm=TRUE says that NA values should be ignored when computing the mean.\n\n2.3.3 Visualizing data\nWe can visualize the data using ggplot. For this we have to specify the mapping aesthetics, we plot the bill length on the x-axis, the depth on the y-axis, colour by species and plot the data as points. The labs() function allows us to customize the graph labels.\n\nCodeggplot(penguins,aes(x=bill_length_mm,y=bill_depth_mm,colour=species)) +\n  geom_point() +\n  labs(title=\"Penguin bill length vs depth\",\n       x=\"Bill length  (mm)\",y=\"Bill depth (mm)\",\n       colour=\"Penguin species\",\n       caption=\"Palmer Station Antarctica LTER\")\n\n\n\n\n\n\n\n\n2.3.3.1 Add regression lines\nAs an aside we note the Simpson’s paradox, in the overall dataset the bill depth declines with length, but if we look separately within each species the bill depth increases with bill length. To make that explicit we can add regression lines using the geom_smooth function using lm (linear model) as the smoothing method.\n\nCodeggplot(penguins,aes(x=bill_length_mm,y=bill_depth_mm,colour=species)) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  geom_smooth(method=\"lm\", colour=\"black\") +\n  labs(title=\"Penguin bill length vs depth\",\n       x=\"Bill length  (mm)\",y=\"Bill depth (mm)\",\n       colour=\"Penguin species\",\n       caption=\"Palmer Station Antarctica LTER\")\n\n\n\n\n\n\n\nThe first geom_smooth() function will add a regression line for each species, distinguished by colour in the plot aesthetics. Overriding the colour argument in the second geom_smooth() function will forget that the data was coloured by species and add the black regression line run on the entire dataset.\n\n2.3.4 More data manipulations\nThere are several common data manipulation steps that we will employ frequently.\n\n2.3.4.1 Filtering rows\nOften we are only interested in subsets of the data, we can filter the rows in the dataset by using the filter verb from the dplyr package that is part of tidyverse. For example, if we want to take the previous plot but only show it for penguins on the island of Biscoe we can filter the data accordingly before plotting it.\n\nCodepenguins |&gt;\n  filter(island==\"Biscoe\") |&gt;\nggplot(aes(x=bill_length_mm,y=bill_depth_mm,colour=species)) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  geom_smooth(method=\"lm\", colour=\"black\") +\n  labs(title=\"Penguin bill length vs depth\",\n       subtitle=\"Biscoe island only\",\n       x=\"Bill length  (mm)\",y=\"Bill depth (mm)\",\n       colour=\"Penguin species\",\n       caption=\"Palmer Station Antarctica LTER\")\n\n\n\n\n\n\n\n\n2.3.4.2 Selecting columns\nInstead of filtering rows it can be useful to select a subset of the columns to remove columns we don’t need and de-clutter the dataset. This is especially useful when producing tables. If we want a table of the numeric data fields of all female Adelie penguins on the island of Biscoe observed in 2007 we can filter by sex and island and select the columns we want.\n\nCodepenguins |&gt;\n  filter(island==\"Biscoe\", sex==\"female\", species==\"Adelie\", year==2007) |&gt;\n  select(where(is.numeric),-year) \n\n# A tibble: 5 × 4\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1           37.8          18.3               174        3400\n2           35.9          19.2               189        3800\n3           35.3          18.9               187        3800\n4           40.5          17.9               187        3200\n5           37.9          18.6               172        3150\n\n\n\n2.3.4.3 Mutating data\nWe often want to change data fields, or compute new columns from existing ones. For example, if we want to convert the body mass from g to kg we can add a new column using mutate for that.\n\nCodepenguin_selection &lt;- penguins |&gt;\n  filter(island==\"Biscoe\", sex==\"female\", species==\"Adelie\", year==2007) |&gt;\n  mutate(body_mass_kg=body_mass_g/1000) |&gt;\n  select(where(is.numeric),-year,-body_mass_g)\n\npenguin_selection\n\n# A tibble: 5 × 4\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_kg\n           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;        &lt;dbl&gt;\n1           37.8          18.3               174         3.4 \n2           35.9          19.2               189         3.8 \n3           35.3          18.9               187         3.8 \n4           40.5          17.9               187         3.2 \n5           37.9          18.6               172         3.15\n\n\n\n2.3.4.4 Pivoting data\nThe data in our penguin_selection dataset above is in wide form, all the different variables are in their own column. Often it is useful to convert it to long form, where we only have one value column with the numeric values and another column specifying the type of measurement. In this case it is useful to add an identification column so that we know which measurements belong to the same penguin. We can just label the penguins by row number.\n\nCodepenguin_selection_long &lt;- penguin_selection |&gt;\n  mutate(ID=row_number()) |&gt;\n  pivot_longer(-ID,names_to=\"Metric\",values_to=\"Value\")\n\npenguin_selection_long |&gt; head()\n\n# A tibble: 6 × 3\n     ID Metric            Value\n  &lt;int&gt; &lt;chr&gt;             &lt;dbl&gt;\n1     1 bill_length_mm     37.8\n2     1 bill_depth_mm      18.3\n3     1 flipper_length_mm 174  \n4     1 body_mass_kg        3.4\n5     2 bill_length_mm     35.9\n6     2 bill_depth_mm      19.2\n\n\nWe can do the reverse transformation, going from long form to wide form, using pivot_wider.\n\nCodepenguin_selection_long |&gt;\n  pivot_wider(names_from = Metric,values_from = Value)\n\n# A tibble: 5 × 5\n     ID bill_length_mm bill_depth_mm flipper_length_mm body_mass_kg\n  &lt;int&gt;          &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n1     1           37.8          18.3               174         3.4 \n2     2           35.9          19.2               189         3.8 \n3     3           35.3          18.9               187         3.8 \n4     4           40.5          17.9               187         3.2 \n5     5           37.9          18.6               172         3.15\n\n\nThis recovers the previous form of the data, with the added ID column.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R, RStudio, and the tidyverse</span>"
    ]
  },
  {
    "objectID": "intro/intro_to_r.html#canadian-data-packages",
    "href": "intro/intro_to_r.html#canadian-data-packages",
    "title": "\n2  R, RStudio, and the tidyverse\n",
    "section": "\n2.4 Canadian data packages",
    "text": "2.4 Canadian data packages\nDuring the course of this book we will make heavy use of several R packages to facilitate data access to Canadian data, we will introduce them in this chapter.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R, RStudio, and the tidyverse</span>"
    ]
  },
  {
    "objectID": "intro/intro_cansim.html",
    "href": "intro/intro_cansim.html",
    "title": "\n3  Introduction to the cansim package\n",
    "section": "",
    "text": "The cansim R package (von Bergmann and Shkolnik 2021) interfaces with the StatCan NDM that replaces the former CANSIM tables. It can be queried for\n\nwhole tables\nspecific vectors\ndata discovery searching through tables\n\nIt encodes the metadata and allows to work with the internal hierarchical structure of the fields.\nLarger tables can also be imported into a local SQLite database for reuse across sessions without the need to re-download the data, and better performance when subsetting the data or performing other basic data operations at the database level before loading the data into memory.\nData discovery can be cumbersome, the list_cansim_cubes function from the cansim package fetches the newest list of all available tables and can be filtered by survey, release date or dates of data coverage. The table list is cached for the duration of the R session. The search_cansim_cubes function provides a convenient shortcut to narrow down this list.\nIn some cases searching the web for “StatCan Table xxxx”, where “xxxx” contains search phrases for the data of interest, is sometimes a useful way to discover data. In reverse, we can bring up the StatCan webpage for a specific table number using the view_cansim_webpage function and explore the data via the web interface. Especially for large datasets this can be a faster way to determine if a specific table contains the information we are interested in without first having to download the data.\nTo get overview information for a table we have already downloaded the get_cansim_table_overview function provides a high-level overview over the variables contained in the table. The get_cansim_column_list function returns a list of the available columns or dimensions in the table, and get_cansim_column_categories returns the list of levels in a specific dimension. The get_cansim_table_nots provides the data notes that can hold important information to guide interpretation of some of the dimensions or levels.\nThe data is accessed via get_cansim function, or alternatively the get_cansim_sqlite function that stores the data permanently for use across R sessions in a local SQLite database. By default the English language tables are accessed, setting the language=\"fr\" parameter changes that to the French version. The SQLite option is especially useful for larger tables. The cansim package will emit a warning if an SQLite table is outdated and newer data is available, if the auto_refresh=TRUE option is passed to the function call it will automatically download any new data if available. When accessing data from the SQLite version we can use normal dplyr verbs to filter the data or perform basic select, group_by or summarize operations before calling collect_and_normalize to fetch the result from the database and enrich it with metadata.\nMetadata added by the cansim package includes converting the dimension values to factors and adding information on the hierarchical structure of the levels. Moreover, the package creates a native Date field and a val_norm field with normalized values. The values shipped by StatCan are sometimes expressed in “thousands of units”, the val_norm converts this to base units for easier interpretation and uniformity across tables.\nMore information can be found in the package documentation and the package vignettes.\nTo install the package from cran use\n\nCodeinstall.packages(\"cansim\")\n\n\n\n\n\n\n\n\nvon Bergmann, Jens, and Dmitry Shkolnik. 2021. Cansim: Functions and Convenience Tools for Accessing Statistics Canada Data Tables. https://mountainmath.github.io/cansim/.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to the **cansim** package</span>"
    ]
  },
  {
    "objectID": "intro/intro_cancensus.html",
    "href": "intro/intro_cancensus.html",
    "title": "\n4  Introduction to the cancensus package\n",
    "section": "",
    "text": "The cancensus R package (von Bergmann, Shkolnik, and Jacobs 2022) interfaces with the CensusMapper API server. It can be queried for\n\ncensus geographies for census years 1996 through 2021\ncensus profile data for census years 1996 through 2021\nsome census custom tabulations\nhierarchical metadata of census variables\nsome non-census data that comes on census geographies, e.g. T1FF taxfiler data\n\nA slight complication, the cancensus package needs an API key. You can sign up for one for free on CensusMapper.\nOnce you have your API key it’s useful to store it as an environment variable in your .Renviron configuration file so it’s available in all your R sessions.\n\nCodeinstall.packages(\"cancensus\")\n\ncancensus::set_api_key(key = \"CensusMapper_XXXX...XXXX\", install=TRUE)\n\n\nBy default {cancensus} caches downloaded census data, which makes it easier and faster to re-run analysis and protects from overusing the CensusMapper API quota. To use caching a local path needs to be designated for data caching. The cache is shared across R sessions.\n\nCodecancensus::set_cache_path(cache_path = \"&lt;local path of cache data&gt;\", install=TRUE)\n\n\n{cancensus} provides convenient access to census data. Calls to {cancensus} require to spectify\n\nThe dataset, for example “CA21” for the 2021 Canadian census. A list of available datasets can be accessed via cancensus::list_census_datasets().\nThe regions to access the data for, this is a list keyed by geographic levels. For example, to access data for the Vancouver census metropolitan area it would be list(CMA=\"59933\"), for the City of Toronto it would be list(CSD=\"3520005\"). Region parameters can contain several regions of the same type or mix regions of different type. For example, to access data for the region covered by the Vancouver School Board, we need to assemble two CSDs and three CTs list(CSD=c(\"5915022\",\"5915803\"),CT=c(\"9330069.04\",\"9330069.03\",\"9330069.02\")). This allows pinpointing what geographic region we are interested in.\nThe geographic level to query the data for. This simply are the regions specified in the regions parameter, but it could also be any geographic level equal to or lower than the lowest level geographic region specified in the regions parameter. Valid level identifiers are DB for dissemination blocks, DA for dissemination areas, EA for enumeration areas for the 1996 census, CT for census tracts, CSD for census subdivisions, CMA for census metropolitan areas or census agglormerations, CD for census districts, PR for provinces or territories and C for country level data. Geographic regions can also be assembled using the CensusMapper API GUI tool, CSD and higher level geographies can be explored or searched programmatically via the list_census_regions() or search_census_regions() functions.\nThe vectors parameter allows to specify which census variables to query. By default the data comes with population, dwelling and household counts, other census variables can be explored and selected via the CensusMapper API GUI tool or explored or searched programmatically via the list_census_vectors() or find_census_vectors() functions. There are also helper functions to select variables using the internal CensusMapper metadata and hierarchy of census variables via the child_census_vectors() function. For finer control over the names of the returned census variable the vectors parameter can be a named vector.\nThe geo_format parameters allows to select if geographic data should also be downloaded, and if yes, in what format. In this post we will only access data via the modern “sf” format, but data can also be accessed in the legacy “sp” spatial data format.\n\nAs an example we will retrieve the share of the population in Toronto, Mississauga, and Brampton spending 30% or more of income on shelter costs in 2016.\n\nCodelibrary(cancensus)\nlibrary(dplyr)\nregions &lt;- list(CSD=c(\"3520005\",\"3521005\",\"3521010\"))\nvectors &lt;- c(shelter_cost_burdened=\"v_CA16_4889\", shelter_base = \"v_CA16_4886\")\n\ndata &lt;- get_census(dataset = \"CA16\", regions=regions, vectors=vectors)\ndata %&gt;% \n  mutate(`Share shelter cost burdened`=shelter_cost_burdened/shelter_base) |&gt;\n  select(GeoUID,`Region Name`,`Share shelter cost burdened`)\n\n# A tibble: 3 × 3\n  GeoUID  `Region Name`    `Share shelter cost burdened`\n  &lt;chr&gt;   &lt;fct&gt;                                    &lt;dbl&gt;\n1 3520005 Toronto (C)                              0.296\n2 3521005 Mississauga (CY)                         0.264\n3 3521010 Brampton (CY)                            0.305\n\n\n\n\n\n\n\n\nvon Bergmann, Jens, Dmitry Shkolnik, and Aaron Jacobs. 2022. Cancensus: R Package to Access, Retrieve, and Work with Canadian Census Data and Geography. https://mountainmath.github.io/cancensus/.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introduction to the **cancensus** package</span>"
    ]
  },
  {
    "objectID": "intro/intro_cmhc.html",
    "href": "intro/intro_cmhc.html",
    "title": "\n5  Introduction to the cmhc package\n",
    "section": "",
    "text": "The cmhc R package (von Bergmann 2022) interfaces with the CMHC Housing Market Information Portal (HMIP) and allows programmatic and reproducible access to CMHC data. This gives access to data from four major CMHC surveys\n\nStarts and Completions Survey (Scss), which has data on housing construction covering starts, completions, units under construction, length of construction, absorbed and unabsorbed units and their prices.\nRental Market Survey (Rms), which surveys the purpose-built rental market on an annual (and for some time twice-annual) basis. It has data on vacancy rates, availability rates, rents, fixed sample rent change and the overall rental universe by bedroom type, structure size, and year of construction.\nSecondary Rental Market Survey (Srms), which covers parts of the secondary market rental market with data on condominium apartment vacancy rates, rents, and number and share of rented units, as well as some information on other secondary rentals.\nSenior’s housing (Seniors), which gives data on seniors housing of various levels of assistance.\nCensus data (Census), which holds several housing related cross-tabulations.\nCore Housing Need (Core Housing Need) related cross-tabulations.\n\nThe package is designed to work in conjunction with the cancensus package and census geographic identifiers.\nTo install the package from CRAN use.\n\nCodeinstall.packages(\"cmhc\")\n\n\nThe nature of the CMHC backend makes it at times challenging to find data, the cmhc package has several convenience functions to facilitate data discovery. The list_… functions, for example list_cmhc_surveys() list options. The select_cmhc_table() allows the interactive selection of data tables in the console, and returns the syntax for the desired function call to acquire the data.\n\n\n\n\n\n\nvon Bergmann, Jens. 2022. Cmhc: R Package to Access, Retrieve, and Work with CMHC Data. https://mountainmath.github.io/cmhc/.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to the **cmhc** package</span>"
    ]
  },
  {
    "objectID": "intro/tongfen.html",
    "href": "intro/tongfen.html",
    "title": "\n6  Introduction to the tongfen package\n",
    "section": "",
    "text": "The tongfen R package (von Bergmann 2021) facilitates making data on different geometries comparable.\nTongFen (通分) means to convert two fractions to the least common denominator, typically in preparation for further manipulation like addition or subtraction. In English, that’s a mouthful and sounds complicated. But in Chinese there is a word for this, TongFen, which makes this process appear very simple.\nWhen working with geospatial datasets we often want to compare data that is given on different regions. For example census data and election data. Or data from two different censuses. To properly compare this data we first need to convert it to a common geography. The process to do this is quite analogous to the process of TongFen for fractions, so we appropriate this term to give it a simple name. Using the tongfen package, preparing data on disparate geographies for comparison by converting them to a common geography is as easy as typing tongfen.\nIn particular, the package has a number of convenience functions to facilitate making Canadian census data comparable through time, making it easy to perform longitudinal analysis on fine geographies based on the Canadian Census. Essentially, the tongfen package creates a semi-custom tabulation based on Dissemination Block, Dissemination Area, or Census Tract geographies.\nThese semi-custom tabulations are created in three steps:\n\nCreate a correspondence table for geographies from different censuses. By default the official StatCan correspondence files are used for that, but these only exist back to 2001 when the current geographic system based on dissemination blocks and dissemination areas started. To go back further, when enumeration areas were the basic building block, we need to rely on geospatial matching of the areas to create a harmonized common geography.\nCreate metadata that contains information about how the census variables of interest can be aggregated in the case where geographies get joined. For example, if we are interested in the share of households in low income, we need to know what this share is based on in order to correctly aggregate it up. CensusMapper holds detailed metadata, so this process is automated.\nJoin geographies and aggregate census data as described in the correspondence table from Step 1 and the metadata in step 2.\n\nThe result of this process is a semi-custom tabulation of the data we want that is created on the fly, at the price of coming on a slightly coarser geography than the original input geographies in cases where geographies had to be joined to create the harmonized geography.\nTo install the package from CRAN use\n\nCodeinstall.packages(\"tongfen\")\n\n\n\n\n\n\n\n\nvon Bergmann, Jens. 2021. Tongfen: R Package to Make Data Based on Different Geographies Comparable. https://mountainmath.github.io/tongfen/.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to the **tongfen** package</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/basic_descriptive.html",
    "href": "basic_descriptive/basic_descriptive.html",
    "title": "Basic descriptive analysis",
    "section": "",
    "text": "In this section we will look at how to do basic descriptive analysis. The questions we ask here will be quite simple, for example: How has income changed over time? Or: Which areas of Toronto have the highest incomes?\nThe accompanying analysis won’t be very involved, sometimes we will compute percentages or make other simple data manipulations, but generally the analysis will be quite straight-forward. We will focus on how to find data sources that can inform on our question, how to get the data, and how to present and interpret it.",
    "crumbs": [
      "Basic descriptive analysis"
    ]
  },
  {
    "objectID": "basic_descriptive/cerb.html",
    "href": "basic_descriptive/cerb.html",
    "title": "\n7  Geography of CERB\n",
    "section": "",
    "text": "7.1 Question\nIn 2020 Canada introduced the COVID-19 Emergency Recovery Benefit (CERB), a program to support people ring the pandemic.\nWhere did CERB benefits go?",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Geography of CERB</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cerb.html#data-sources",
    "href": "basic_descriptive/cerb.html#data-sources",
    "title": "\n7  Geography of CERB\n",
    "section": "\n7.2 Data sources",
    "text": "7.2 Data sources\nStandard T1FF taxfiler data has this for large geographies, to understand fine geographic distribution we turn to Census data from the 2021 census, which reports on 2020 income. The census dictionary explains\n\nCanada Emergency Response Benefit (CERB) payments received during the reference period. This benefit was intended to provide financial support to employees and self‑employed Canadians who had lost their job or were working fewer hours due to the COVID‑19 pandemic and the public health measures implemented to minimize the spread of the virus.\n\nCensus income data is taken directly from T1 tax returns and linked at the individual person level.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Geography of CERB</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cerb.html#data-acquisition",
    "href": "basic_descriptive/cerb.html#data-acquisition",
    "title": "\n7  Geography of CERB\n",
    "section": "\n7.3 Data acquisition",
    "text": "7.3 Data acquisition\nWe can use the CensusMapper API tool and search for “COVID-19” in the Variable Selection tab to locate available census variables. Since we are interested in where people lived that received the benefit we select v_CA21_593, the number of recipients, as well as v_CA21_554, the baseline of people 15 years or older who are in principle eligible for this benefit.\nWe also need to decide which region we want to investigate, let’s take a look at the City of Ottawa. We can select the city in the Region Selection tab and read off the geographic identifier 3506008 for the City of Ottawa in the Overview tab.\nNow we have all we need to pull in the data, we just need to decide on the geographic granularity. Let’s use census tracts, a standard geographic region aiming to capture between 2,500 and 7,500 people in metropolitan areas. We also specify that we want the geographies, not just the tabular data.\n\nCodelibrary(cancensus)\nottawa_cerb &lt;- get_census(\"CA21\",regions=list(CSD=\"3506008\"),\n                          vectors=c(cerb=\"v_CA21_593\", base=\"v_CA21_554\"),\n                          level=\"CT\", geo_format=\"sf\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Geography of CERB</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cerb.html#data-preparation",
    "href": "basic_descriptive/cerb.html#data-preparation",
    "title": "\n7  Geography of CERB\n",
    "section": "\n7.4 Data preparation",
    "text": "7.4 Data preparation\nTo understand the geographic distribution we compute the percentage of people 15 years and over receiving CERB. Generally in this book we work in the tidyverse to help with data manipulation and visualization, so we load that library too.\n\nCodelibrary(tidyverse)\nplot_data &lt;- ottawa_cerb |&gt;\n  mutate(Share=cerb/base)\n\n\nThere is not much to do, computing a percentage is a simple division. The mutate verb creates a new column called Share holding the computed ratios.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Geography of CERB</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cerb.html#analysis-and-visualization",
    "href": "basic_descriptive/cerb.html#analysis-and-visualization",
    "title": "\n7  Geography of CERB\n",
    "section": "\n7.5 Analysis and visualization",
    "text": "7.5 Analysis and visualization\nAll that’s left is to visualize the data. To plot geographic data we use ggplot and the geom_sf geometry. We need to tell it how to colour the map, the aesthetic, and we specify to fill each area by the share of CERB recipients.\n\nCodeggplot(plot_data) +\n  geom_sf(aes(fill=Share))\n\n\n\n\n\n\n\nTo make this a little nicer we add labels, remove the coordinate grid and choose nicer colours and reduce the boundary line size.\n\nCodeggplot(plot_data) +\n  geom_sf(aes(fill=Share)) +\n  scale_fill_viridis_c(labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"CERB recipients in the City of Ottawa\",\n       fill=\"Share of people\\n15+ reveiving\\nCERB\",\n       caption=\"StatCan Census 2021\")\n\n\n\n\n\n\n\nIt is difficult to see the central parts, we might want to zoom in a little. At the same time, it might be useful to add in Gatineau and surrounding municipalities, so maybe we want the data for the entire metro area.\nTo do this we copy and paste the code from above and chain it into a single pipe, from data acquisition (using the CMA 505 for Ottawa CMA), computing the share, to plotting and cutting the region to the central parts by looking at the grid from the first map.\n\nCodeget_census(\"CA21\",regions=list(CMA=\"505\"),\n                          vectors=c(cerb=\"v_CA21_593\", base=\"v_CA21_554\"),\n                          level=\"CT\", geo_format=\"sf\") |&gt;\n  mutate(Share=cerb/base) |&gt;\n  ggplot() +\n  geom_sf(aes(fill=Share)) +\n  scale_fill_viridis_c(labels=scales::percent) +\n  coord_sf(datum=NA, xlim=c(-76,-75.5), ylim=c(45.3,45.5)) +\n  labs(title=\"CERB recipients in Ottawa\",\n       fill=\"Share of people\\n15+ reveiving\\nCERB\",\n       caption=\"StatCan Census 2021\")\n\n\n\n\n\n\n\nThis brings out the central regions much better. We could also try this with finer geographies, setting the level to dissemination areas instead of census tracts. The same code as before works, except changing the level=\"CT\" to level=\"DA\".\n\nCodeget_census(\"CA21\",regions=list(CMA=\"505\"),\n                          vectors=c(cerb=\"v_CA21_593\", base=\"v_CA21_554\"),\n                          level=\"DA\", geo_format=\"sf\") |&gt;\n  mutate(Share=cerb/base) |&gt;\n  ggplot() +\n  geom_sf(aes(fill=Share)) +\n  scale_fill_viridis_c(labels=scales::percent) +\n  coord_sf(datum=NA, xlim=c(-76,-75.5), ylim=c(45.3,45.5)) +\n  labs(title=\"CERB recipients in Ottawa\",\n       fill=\"Share of people\\n15+ reveiving\\nCERB\",\n       caption=\"StatCan Census 2021\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Geography of CERB</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cerb.html#interpretation",
    "href": "basic_descriptive/cerb.html#interpretation",
    "title": "\n7  Geography of CERB\n",
    "section": "\n7.6 Interpretation",
    "text": "7.6 Interpretation\nWe notice substantial differences in the share of people receiving CERB benefits, with rural areas generally having lower shares, and central areas being more mixed, varying between under 10% to well over 40% of people 15 years and over receiving CERB. Generally areas with lower incomes have benefited more from CERB.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Geography of CERB</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cars_vs_suvs.html",
    "href": "basic_descriptive/cars_vs_suvs.html",
    "title": "\n8  Cars vs SUVs in Canada\n",
    "section": "",
    "text": "8.1 Question\nPrivate motor vehicles in Canada seem to be getting larger and it feels like SUVs and light trucks are taking over. This subjective feeling prompts us to ask the following question to check if this is just our imagination or a real phenominon.\nAre SUVs and light trucks taking over in Canada?\nThis question is somewhat vague, it’s not clear what taking over means. But the question is clear enough to get us started on some descriptive analysis.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cars vs SUVs in Canada</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cars_vs_suvs.html#data-sources",
    "href": "basic_descriptive/cars_vs_suvs.html#data-sources",
    "title": "\n8  Cars vs SUVs in Canada\n",
    "section": "\n8.2 Data sources",
    "text": "8.2 Data sources\nData discovery can be challenging, but just typing “statcan motor vehicle sales” into a search engine is a good start and gets us to the StatCan table enumerating data on new motor vehicle sales. We can also use the built-in search functionality in the {cansim} package.\n\nCodelibrary(dplyr)\nlibrary(ggplot2)\nlibrary(cansim)\n\nsearch_cansim_cubes(\"motor vehicle sales\") |&gt;\n  select(cansim_table_number,cubeTitleEn,cubeStartDate,cubeEndDate)\n\n# A tibble: 2 × 4\n  cansim_table_number cubeTitleEn                      cubeStartDate cubeEndDate\n  &lt;chr&gt;               &lt;chr&gt;                            &lt;date&gt;        &lt;date&gt;     \n1 20-10-0001          New motor vehicle sales          1946-01-01    2024-02-01 \n2 20-10-0002          New motor vehicle sales, by typ… 2010-01-01    2023-01-01 \n\n\nThere are two tables with motor vehicle sales, we can inspect them on the web or via the {cansim} package. The second table covers a much shorter time period, and is also less recent. We will check out the first table to see if it fits our needs.\nTo access the web we can simply type view_cansim_webpage(\"20-10-0001\") into the console, which will open the StatCan webpage for Table 20-10-0001. Getting table overview data via the {cansim} package requires to load the table first, which can be slow for larger tables.\n\nCodeget_cansim_table_overview(\"20-10-0001\")\n\n\nThis tells us that Table 20-10-0001 might have the information we need, we check the table notes to better understand what “Trucks” entails, selecting the two columns we are interested in.\n\nCodeget_cansim_table_notes(\"20-10-0001\") %&gt;% \n  select(`Member Name`,Note) %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\nMember Name\nNote\n\n\n\nNA\nPrior to 1953, data for Canadian and United States manufactured vehicles and overseas manufactured vehicles are not segregated.\n\n\nBritish Columbia and the Territories\nIncludes Yukon, Northwest Territories and Nunavut.\n\n\nTrucks\nTrucks include minivans, sport-utility vehicles, light and heavy trucks, vans and buses.\n\n\nTotal, overseas\nIncludes Japan and other countries.\n\n\nNA\nSeasonally adjusted data for the New Motor Vehicle Sales survey are available for the period between January 1991 to February 2012.\n\n\n\n\n\nIt looks like “Trucks” does includes SUVs, but next to light trucks it also includes heavy trucks and buses. It also includes minivans, and thinking back at our original question, we might want to refine it to include minivans.\nThis allows us to separate passenger cars from basically everything else. Thinking that heavy truck and bus sales probably only make up a small portion, we could use that as a stand-in for our “SUVs and light trucks” in our question. But the match is not ideal and this leaves questions open.\nMaybe Table 20-10-0002 works better for our purposes, time to look at the table overview.\n\nCodeget_cansim_table_overview(\"20-10-0002\")\n\n\nThe frequency is only annual as opposed to the monthly data from the previous table, but the breakdown of vehicle types looks much better for our purposes, it allows us to distinguish light trucks from heavy trucks and buses. Time to check the table notes for more details on the definitions.\n\nCodeget_cansim_table_notes(\"20-10-0002\") %&gt;% \n  select(`Member Name`,Note) %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\nMember Name\nNote\n\n\n\nBritish Columbia and the Territories\nIncludes Yukon, Northwest Territories and Nunavut.\n\n\nTrucks\nTrucks include minivans, sport-utility vehicles, light and heavy trucks, vans and buses.\n\n\nLight trucks\nLight trucks: include minivans, sport-utility vehicles, light trucks and vans.\n\n\nHeavy trucks\nHeavy trucks: include class 4, 5, 6, 7 and 8 trucks.\n\n\n\n\n\nThis looks like it fits what we need, we want to compare unit sales of Passenger cars to Light trucks.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cars vs SUVs in Canada</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cars_vs_suvs.html#data-acquisition",
    "href": "basic_descriptive/cars_vs_suvs.html#data-acquisition",
    "title": "\n8  Cars vs SUVs in Canada\n",
    "section": "\n8.3 Data acquisition",
    "text": "8.3 Data acquisition\nGetting the data is easy now. The {cansim} package will automatically add a native Date column, to convert annual data to dates it defaults to July 1st of that year. While it is a sensible default to assign a mid-year date to annual data, later on for plotting it will be more convenient for us to set the date at January 1st, so we override the default using the optional default_month argument.\n\nCodedata &lt;- get_cansim(\"20-10-0002\", default_month = 1)\n\ndata |&gt; select(Date,GEO,`Vehicle type`,Sales,val_norm) %&gt;%\n  head()\n\n# A tibble: 6 × 5\n  Date       GEO    `Vehicle type`            Sales      val_norm\n  &lt;date&gt;     &lt;chr&gt;  &lt;fct&gt;                     &lt;fct&gt;         &lt;dbl&gt;\n1 2010-01-01 Canada Total, new motor vehicles Units       1584499\n2 2010-01-01 Canada Total, new motor vehicles Dollars 52315609000\n3 2010-01-01 Canada Passenger cars            Units        710214\n4 2010-01-01 Canada Passenger cars            Dollars 18982437000\n5 2010-01-01 Canada Trucks                    Units        874285\n6 2010-01-01 Canada Trucks                    Dollars 33333173000\n\n\nQuick inspection of the data, using the columns we identified in the overview, helps identify the basic structure of the data.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cars vs SUVs in Canada</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cars_vs_suvs.html#data-preparation",
    "href": "basic_descriptive/cars_vs_suvs.html#data-preparation",
    "title": "\n8  Cars vs SUVs in Canada\n",
    "section": "\n8.4 Data preparation",
    "text": "8.4 Data preparation\nThere is not much data preparation needed, we just filter down to the data we are interested in.\n\nCodeplot_data &lt;- data |&gt;\n  filter(`Vehicle type` %in% c(\"Passenger cars\",\"Light trucks\"),\n         Sales==\"Units\",\n         GEO==\"Canada\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cars vs SUVs in Canada</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cars_vs_suvs.html#analysis-and-visualization",
    "href": "basic_descriptive/cars_vs_suvs.html#analysis-and-visualization",
    "title": "\n8  Cars vs SUVs in Canada\n",
    "section": "\n8.5 Analysis and visualization",
    "text": "8.5 Analysis and visualization\nTime to lake a look what this looks like, to plot we filter for the overall Canadian data series, and tell ggplot to map Date on the x-axis, the values colum `VALUE` on the y-axis, and colour by vehicle type.\n\nCodeggplot(plot_data,aes(x=Date,y=VALUE,colour=`Vehicle type`)) +\n  geom_line() \n\n\n\n\n\n\n\nThis is looking good, time to clean up the graph a bit. We add markers for the data points, nicer axis labels, as well as a title and labels.\n\nCodeggplot(plot_data,aes(x=Date,y=VALUE,colour=`Vehicle type`)) +\n  geom_point(shape=21) +\n  geom_line() +\n  scale_y_continuous(labels=scales::comma) +\n  scale_color_manual(labels=c(\"Light trucks\"=\"Light trucks, SUVs,\\nminvans and vans\"),\n                     values=c(\"Light trucks\"=\"brown\",\"Passenger cars\"=\"steelblue\")) +\n  labs(title=\"New motor vehicle sales in Canada\",\n       x=NULL,y=\"Annual number of vehicles.\",\n       caption=\"StatCan Table 20-10-0002\")\n\n\n\n\n\n\n\nThis answers our question in that more light trucks, SUVs, minivans and vans are sold than cars, and the gap has been growing. But the data only starts in 2010, and we suspect that things weren’t always this way. At what point did SUVs and light trucks overtake new car sales?\nTo answer than we need to jump back and load the other time series. It won’t let us separate out heavy trucks and buses, but we can estimate how bad the difference is by comparing it to this data.\nWe load the data and filter it down to the parts that we are interested in.\n\nCodedata2 &lt;- get_cansim(\"20-10-0001\")\n\nplot_data2 &lt;- data2 |&gt;\n  filter(`Vehicle type` %in% c(\"Passenger cars\",\"Trucks\"),\n         Sales==\"Units\",\n         `Origin of manufacture`==\"Total, country of manufacture\",\n         `Seasonal adjustment`==\"Unadjusted\",\n         GEO==\"Canada\")\n\n\nA quick plot gives us a general idea what this looks like.\n\nCodeplot_data2 %&gt;%\n  ggplot(aes(x=Date,y=VALUE,colour=`Vehicle type`)) +\n  geom_line()\n\n\n\n\n\n\n\nThere is a strong seasonal pattern in vehicle sales, for now we will just aggregate it to annual sales so we can compare it with the previous data. For this we extract the Year from the Date column, group by Year and Vehicle type and summarize by adding up the `VALUE` column. We added a count column to keep track how many months we added up so we can later ensure we are only showing years for which we have complete data.\n\nCodeplot_data2_annual &lt;- plot_data2 |&gt;\n  mutate(Year=strftime(Date,\"%Y\")) |&gt;\n  group_by(Year,`Vehicle type`) |&gt;\n  summarise(VALUE=sum(VALUE), n=n(),.groups=\"drop\") |&gt;\n  mutate(Date=as.Date(paste0(Year,\"-01-01\"))) |&gt;\n  filter(n==12)  # only use years with full 12 months of data\n\nggplot(plot_data2_annual,aes(x=Date,y=VALUE,colour=`Vehicle type`)) +\n  geom_line()\n\n\n\n\n\n\n\nTime to combine this with our previous data. This tells us that the most interesting change happened 1985 and onward, so we will discard earlier years. One quick sanity check is to see if the annual passenger car sales derived from the two series agree for the years where they are in common. Here we join the two data tables by Date and Vehicle type in order to compare the two estimate. We rename the VALUE column on the first one in order to avoid name conflicts.\n\nCodeplot_data %&gt;%\n  filter(`Vehicle type`==\"Passenger cars\") %&gt;%\n  select(Date,`Vehicle type`,VALUE1=VALUE) %&gt;%\n  left_join(plot_data2_annual,by=c(\"Date\",\"Vehicle type\")) %&gt;%\n  mutate(diff=VALUE1-VALUE) %&gt;%\n  select(Year,VALUE1,VALUE,diff)\n\n# A tibble: 14 × 4\n   Year  VALUE1  VALUE  diff\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2010  710214 710214     0\n 2 2011  691079 691079     0\n 3 2012  759024 759024     0\n 4 2013  760924 760920     4\n 5 2014  760449 760449     0\n 6 2015  712322 712322     0\n 7 2016  661088 661088     0\n 8 2017  646960 646960     0\n 9 2018  586357 586357     0\n10 2019  496851 496851     0\n11 2020  325494 325494     0\n12 2021  327994 327994     0\n13 2022  272408 272408     0\n14 2023  253453 253453     0\n\n\nThe data for all years agrees, except for 2013 where one series counts 4 more passenger cars.\n\nCodebind_rows(plot_data %&gt;% filter(`Vehicle type`!=\"Passenger cars\"),\n          plot_data2_annual %&gt;% filter(Date&gt;=as.Date(\"1985-01-01\"))) %&gt;%\n  ggplot(aes(x=Date,y=VALUE,colour=`Vehicle type`)) +\n  geom_point(shape=21) +\n  geom_line() +\n  scale_y_continuous(labels=scales::comma) +\n  scale_color_manual(labels=c(\"Light trucks\"=\"Light trucks, SUVs,\\nminvans and vans\",\n                              \"Trucks\"=\"Trucks, SUVs,\\nminivans, vans and buses\"),\n                     values=c(\"Light trucks\"=\"brown\",\"Passenger cars\"=\"steelblue\",\n                              \"Trucks\"=\"purple\")) +\n  theme(legend.position = \"bottom\") +\n  labs(title=\"New motor vehicle sales in Canada\",\n       x=NULL,y=\"Annual number of vehicles.\",\n       caption=\"StatCan Tables 20-10-0001, 20-10-0002\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cars vs SUVs in Canada</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/cars_vs_suvs.html#interpretation",
    "href": "basic_descriptive/cars_vs_suvs.html#interpretation",
    "title": "\n8  Cars vs SUVs in Canada\n",
    "section": "\n8.6 Interpretation",
    "text": "8.6 Interpretation\nThis confirms our initial suspicion that the “Trucks” category is dominated by light trucks, SUVs, minivans and vans, at least for the years 2010 onwards where we have data for both. Which gives us confidence to say that truck and SUV sales caught up to passenger cars sales by around 1997, and the two evolved fairly parallel until 2009, after which SUVs and light trucks increased dramatically and passenger car sales fell.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cars vs SUVs in Canada</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/under_construction.html",
    "href": "basic_descriptive/under_construction.html",
    "title": "\n9  Under construction\n",
    "section": "",
    "text": "9.1 Question\nUnits under construction give some indication of construction activity beyond starts and completions.\nHow many homes are currently under construction in Toronto?",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Under construction</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/under_construction.html#data-sources",
    "href": "basic_descriptive/under_construction.html#data-sources",
    "title": "\n9  Under construction\n",
    "section": "\n9.2 Data sources",
    "text": "9.2 Data sources\nCMHC tracks information on housing starts and completions. And the number of homes under construction, that is dwelling units that have started but aren’t yet completed.\nCMHC defines a housing “start” as the time when the foundation is finished, so digging a parking crater and building below ground happens before what CMHC calls a building “start”. This might differ from how one might colloquially think about units under construction, as there can be significant construction activity before a “start”. But this probably comes reasonably close to our question of interest.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Under construction</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/under_construction.html#data-acquisition",
    "href": "basic_descriptive/under_construction.html#data-acquisition",
    "title": "\n9  Under construction\n",
    "section": "\n9.3 Data acquisition",
    "text": "9.3 Data acquisition\nThe cmhc package facilitates importing data from CMHC. This pries data out the Housing Market Information Portal where data is organized across a variety of tables. The easiest way to locate a table of interest is to use the select_cmhc_table() function from the cmhc package in the console to interactively step through the process. In our case, we are interested in data from the Starts and Completions Survey (Scss), look at the Under Construction series, after which we can select to have data broken down by Bedroom Type or Intended Market, where we select the former. Lastly we need to decide the breakdown type, either a level of geography or Historical Time Periods for a fixed geography, which is what we are interested in.\nGoing through this process gives us the code we need to access the data, all we need to do is fill in the geographic identifier. The cmhc package is designed to work in conjunction with other census data, so it uses the same geographic identifiers and translates them to CMHC’s own internal geographic identifiers under the hood. For Toronto, we need to decide if we are interested in the City of the metro area and grab the geographic identifier from the CensusMapper API tool. We will query data for the City of Toronto with standard StatCan geographic identifier “3520005” .\n\nCodelibrary(tidyverse)\nlibrary(cmhc)\nunder_construction &lt;- get_cmhc(survey = \"Scss\", \n                               series = \"Under Construction\", \n                               dimension = \"Dwelling Type\", \n                               breakdown = \"Historical Time Periods\", \n                               geo_uid = \"3520005\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Under construction</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/under_construction.html#data-preparation",
    "href": "basic_descriptive/under_construction.html#data-preparation",
    "title": "\n9  Under construction\n",
    "section": "\n9.4 Data preparation",
    "text": "9.4 Data preparation\nThere is really not much to do here, let’s just inspect what the data looks like\n\nCodeunder_construction |&gt; head()\n\n# A tibble: 6 × 7\n  GeoUID  Date       DateString `Dwelling Type` Value Survey Series            \n  &lt;chr&gt;   &lt;date&gt;     &lt;chr&gt;      &lt;fct&gt;           &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;             \n1 3520005 1998-01-01 Jan 1998   Single            838 Scss   Under Construction\n2 3520005 1998-01-01 Jan 1998   Semi-Detached     132 Scss   Under Construction\n3 3520005 1998-01-01 Jan 1998   Row               838 Scss   Under Construction\n4 3520005 1998-01-01 Jan 1998   Apartment        3008 Scss   Under Construction\n5 3520005 1998-01-01 Jan 1998   All              4816 Scss   Under Construction\n6 3520005 1998-02-01 Feb 1998   Single            738 Scss   Under Construction",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Under construction</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/under_construction.html#analysis-and-visualization",
    "href": "basic_descriptive/under_construction.html#analysis-and-visualization",
    "title": "\n9  Under construction\n",
    "section": "\n9.5 Analysis and visualization",
    "text": "9.5 Analysis and visualization\nWhat’s left is to plot the data, broken out by dwelling type.\n\nCodeggplot(under_construction, aes(x=Date,y=Value,colour=`Dwelling Type`)) +\n  geom_line() +\n  scale_y_continuous(labels=scales::comma) +\n  labs(title=\"City of Toronto dwelling units under construction\",\n       x=NULL,y=\"Number of units\", caption=\"CMHC Scss\")\n\n\n\n\n\n\n\nIt looks like the number of units under construction, especially apartment units, has increased considerably over time. Let’s cross-check that against housing starts. These tend to be quite noisy, so we go to annual frequency instead of monthly. We can adapt the code above for data acquisition and graphing into one chunk.\n\nCodeget_cmhc(survey = \"Scss\", \n         series = \"Starts\", \n         dimension = \"Dwelling Type\", \n         breakdown = \"Historical Time Periods\", \n         frequency = \"Annual\",\n         geo_uid = \"3520005\") |&gt;\n  ggplot(aes(x=Date,y=Value,colour=`Dwelling Type`)) +\n  geom_line() +\n  scale_y_continuous(labels=scales::comma) +\n  labs(title=\"City of Toronto dwelling unit starts\",\n       x=NULL,y=\"Number of units\", caption=\"CMHC Scss\")\n\n\n\n\n\n\n\nStarts have increased, but not that much. Something else must be at play too, let’s look at how length of construction has changed over this timeframe, again using annual data to cut down on noise.\n\nCodeget_cmhc(survey = \"Scss\", \n         series = \"Length of Construction\", \n         dimension = \"Dwelling Type\", \n         breakdown = \"Historical Time Periods\", \n         frequency = \"Annual\",\n         geo_uid = \"3520005\") |&gt;\n  ggplot(aes(x=Date,y=Value,colour=`Dwelling Type`)) +\n  geom_line() +\n  scale_y_continuous(labels=scales::comma) +\n  labs(title=\"City of Toronto dwelling unit starts\",\n       x=NULL,y=\"Average length of construction (months)\",\n       caption=\"CMHC Scss\")\n\n\n\n\n\n\n\nAnd indeed, the length of construction shot up a lot, for apartments from around 13 months in the late 90s to about 30 months around 2020. That means we now have over twice as many construction sites for the same number of units coming to market compared to the late 90s.\nThe sharp increase in construction time for Semi-detached and row houses might well be a data anomaly, where low and dropping number of starts of such units can be disproportionally impacted by a couple of stalled projects.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Under construction</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/under_construction.html#interpretation",
    "href": "basic_descriptive/under_construction.html#interpretation",
    "title": "\n9  Under construction\n",
    "section": "\n9.6 Interpretation",
    "text": "9.6 Interpretation\nThe units under construction has increased a lot in the City of Toronto, due to the combined effects of increasing building starts as well as a more than doubling of average time to complete these units.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Under construction</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html",
    "href": "basic_descriptive/geography_of_income_change.html",
    "title": "\n10  Geography of income change\n",
    "section": "",
    "text": "10.1 Question\nIncomes in a region change by people getting higher (or lower) incomes as well as people moving in and out of a region. We can observe the aggregate effects by looking at change in income statistics.\nWhere and how did incomes change in the City of Vancouver?",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#data-sources",
    "href": "basic_descriptive/geography_of_income_change.html#data-sources",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.2 Data sources",
    "text": "10.2 Data sources\nThe main data sources for fine-geography income data is the census, although custom tabulations of T1FF taxfiler data can offer insight of this on an annual basis at the census tract geography. For our question we are interested in broad temporal ranges, so the 5-year census data will work well.\nWe need to decide which income concept is best suited for our question, it is worthwhile to spend some time with the Census Income Reference Guide to understand how the data was collected and what income concept to use. Prior to 2011 the income data was part of the long form census. In 2011 the mandatory long form was replaced with the voluntary NHS, given people the option to link directly to T1FF taxfiler data or to detail the income data manually. Starting 2016 income data was linked for all people to the T1FF taxfiler data.\nThe question what income concept to use, e.g. individual income, household income, family income, employment income, etc, depends on the particular question we are interested in. For now we will go with family income, trying to understand how the income situation of families varies across Vancouver and across time. Family income is less affected by demographic factors like the distribution of single vs multiple person households, but is still impacted by e.g. differences in shares of seniors vs young families vs families at the peak of their earnings.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#data-acquisition",
    "href": "basic_descriptive/geography_of_income_change.html#data-acquisition",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.3 Data acquisition",
    "text": "10.3 Data acquisition\nWe again use the CensusMapper API tool to locate the internal CensusMapper identifiers for Median Total Income of Economic Families for the years 2006 through 2021. For 2001 the standard census products reported income for census families instead of economic families, so they aren’t directly comparable. As geographic breakdown we choose census tracts.\n\nCodelibrary(tidyverse)\nregions &lt;- list(CSD=\"5915022\")\nincome_vectors &lt;- c(\"2021\"=\"v_CA21_965\",\n                    \"2016\"=\"v_CA16_2447\",\n                    \"2011\"=\"v_CA11N_2456\",\n                    \"2006\"=\"v_CA06_1741\")\n\n\nTo facilitate the data import we write a wrapper function to acquire the census data for each of our four years. For a given census year we create the corresponding dataset identifier and select the appropriate income variable. To reduce clutter we select just the income variable and also keep the geographic identifier, and add the census year to the table.\n\nCodeget_census_data &lt;- function(year){\n  year &lt;- as.character(year)\n  get_census(year,regions=regions,\n             vectors=c(\"ef_income\"=as.character(income_vectors[year])),\n             geo_format=\"sf\",level=\"CT\") |&gt;\n    select(GeoUID,ef_income) |&gt;\n    mutate(Year=year)\n}\n\n\nImporting the data is easy now, we just call our function for each census year and collect it into a data frame.\n\nCodelibrary(cancensus)\nincome_data &lt;- seq(2006,2021,5) |&gt;\n  map_df(get_census_data) \n\n\nLet’s take a quick look.\n\nCodeggplot(income_data) +\n  geom_sf(aes(fill=ef_income)) +\n  scale_fill_viridis_c(option=\"inferno\", labels=scales::dollar) +\n  facet_wrap(~Year) +\n  coord_sf(datum=NA) +\n  labs(title=\"Median economic family income\",\n       fill=\"Current dollars\",\n       caption=\"StatCan Census 2006-2021\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#data-preparation",
    "href": "basic_descriptive/geography_of_income_change.html#data-preparation",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.4 Data preparation",
    "text": "10.4 Data preparation\nLooking at the above graph we can see the geographic variation in each year, but it is difficult to discern geographic trends over time as incomes have gone up a lot during this timeframe. It makes sense to look at inflation-adjusted incomes instead. For this we use annual consumer price index data from StatCan Table 18-10-0005. To simplify things we locate the specific vector v41693271 for the all-time CPI.\n\nCodelibrary(cansim)\ninflation &lt;- get_cansim_vector(\"v41693271\") |&gt;\n  mutate(Year=strftime(Date,\"%Y\")) |&gt;\n  select(Year,CPI=val_norm) |&gt;\n  filter(Year %in% names(income_vectors))\n\ninflation\n\n# A tibble: 4 × 2\n  Year    CPI\n  &lt;chr&gt; &lt;dbl&gt;\n1 2006   109.\n2 2011   120.\n3 2016   128.\n4 2021   142.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#analysis-and-visualization",
    "href": "basic_descriptive/geography_of_income_change.html#analysis-and-visualization",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.5 Analysis and visualization",
    "text": "10.5 Analysis and visualization\nWith this, we can adjust the census data by inflation. We choose to base everything on 2021 dollars.\n\nCodeinflation &lt;- inflation |&gt;\n  mutate(CPI=CPI/last(CPI,order_by = Year))\n\n\nNow we just join the inflation data onto our income data by year, this adds the CPI column from the inflation data frame to our income with the CPI value corresponding to the value in the Year column in each of the two data frames. We then colour by inflation-adjusted income using the same code for graphing as above.\n\nCodeincome_data |&gt;\n  left_join(inflation,by=\"Year\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill=ef_income/CPI)) +\n  scale_fill_viridis_c(option=\"inferno\", labels=scales::dollar) +\n  facet_wrap(~Year) +\n  coord_sf(datum=NA) +\n  labs(title=\"Median economic family income\",\n       fill=\"Constant 2021\\ndollars\",\n       caption=\"StatCan Census 2006-2021\")\n\n\n\n\n\n\n\nThis shows more clearly how incomes have increased over time, but it would be nice to compute the change in income 2006 to 2021 for each individual census tract. But keen observers will notice that some census tracts have changed over the years, making it very difficult to compare data directly.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#data-acquisition-part-2",
    "href": "basic_descriptive/geography_of_income_change.html#data-acquisition-part-2",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.6 Data acquisition (part 2)",
    "text": "10.6 Data acquisition (part 2)\nFortunately the problem of making census data comparable across time has been solved with the tongfen package. This allows us to create a semi-custom tabulation on the fly on a harmonized geography based on census tracts by aggregating census data appropriately. One problem is that medians can’t be aggregated, so we need to either use average income instead or be content that medians can only be approximated. By default the tongfen package aggregates medians as if they were averages and emits a warning. This is the route we will take for this.\nTo start out, we need to create metadata for the tongfen procedure. This is automated for Canadian census data, leveraging the metadata built into CensusMapper.\n\nCodelibrary(tongfen)\nmeta &lt;- meta_for_ca_census_vectors(income_vectors)\n\nmeta\n\n# A tibble: 8 × 10\n  variable  label dataset type  aggregation units rule  parent geo_dataset  year\n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;       &lt;int&gt;\n1 v_CA21_9… 2021  CA21    Orig… Median of … Curr… Medi… v_CA2… CA21         2021\n2 v_CA16_2… 2016  CA16    Orig… Median of … Curr… Medi… v_CA1… CA16         2016\n3 v_CA11N_… 2011  CA11N   Orig… Median of … Curr… Medi… v_CA1… CA11         2011\n4 v_CA06_1… 2006  CA06    Orig… Median of … Curr… Medi… v_CA0… CA06         2006\n5 v_CA21_9… v_CA… CA21    Extra Additive    &lt;NA&gt;  Addi… &lt;NA&gt;   CA21         2021\n6 v_CA16_2… v_CA… CA16    Extra Additive    &lt;NA&gt;  Addi… &lt;NA&gt;   CA16         2016\n7 v_CA11N_… v_CA… CA11N   Extra Additive    &lt;NA&gt;  Addi… &lt;NA&gt;   CA11         2011\n8 v_CA06_1… v_CA… CA06    Extra Additive    &lt;NA&gt;  Addi… &lt;NA&gt;   CA06         2006\n\n\nThe metadata contains our original income data, as well as extra variables needed to properly aggregate the data. Getting the income data on a common geography is easy now.\n\nCodeunified_income_data &lt;- get_tongfen_ca_census(regions,meta)",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#analysis-and-visualization-1",
    "href": "basic_descriptive/geography_of_income_change.html#analysis-and-visualization-1",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.7 Analysis and visualization",
    "text": "10.7 Analysis and visualization\nIn line with what we did before we look at inflation-adjusted income change. To this end we extract the adjustment factor for the 2006-2021 timeframe.\n\nCodeinflation_2006_2021 &lt;- inflation |&gt;\n  filter(Year==\"2006\") |&gt;\n  pull(CPI)\n\n\nWith that we can simply plot the data, mapping the inflation-adjusted percent change 2006 to 2021.\n\nCodeunified_income_data |&gt;\n  ggplot() +\n  geom_sf(aes(fill=`2021`/`2006`*inflation_2006_2021-1)) +\n  scale_fill_viridis_c(option=\"cividis\", labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"Change in economic family income\",\n       fill=\"Change 2006-2021\\n(inflation adjusted)\",\n       caption=\"StatCan Census 2006-2021\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/geography_of_income_change.html#interpretation",
    "href": "basic_descriptive/geography_of_income_change.html#interpretation",
    "title": "\n10  Geography of income change\n",
    "section": "\n10.8 Interpretation",
    "text": "10.8 Interpretation\nIn summary we see that income of economic families changed fastest in the Downtown Eastside, Grandview-Woodlands and Strathcona neighbourhoods, effectively doubling. Incomes increased least on the West Side, where they were already quite high to start with, and increased by about 50% throughout much of the East Side.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geography of income change</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/toronto_children.html",
    "href": "basic_descriptive/toronto_children.html",
    "title": "\n11  Toronto children\n",
    "section": "",
    "text": "11.1 Question\nWe keep reading in the news that the number (and share) of children under the age of 15 declined in the City of Toronto, a fate that’s shared by the City of Vancouver. But is this happening uniformly across the city or are there geographic differences?\nWhere in Toronto is the number (and share) of children under 15 decreasing, and where is it increasing?",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Toronto children</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/toronto_children.html#data-sources",
    "href": "basic_descriptive/toronto_children.html#data-sources",
    "title": "\n11  Toronto children\n",
    "section": "\n11.2 Data sources",
    "text": "11.2 Data sources\nIn Canada we have data on the number of children from two main data sources and their derived products. The census and T1FF taxfiler data. Both are available at sub-city level, although that’s a custom tabulation for T1FF taxfiler data. For this post we will go with census data since the T1FF custom tabulations we have on CensusMapper only go up to 2018.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Toronto children</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/toronto_children.html#data-acquisition",
    "href": "basic_descriptive/toronto_children.html#data-acquisition",
    "title": "\n11  Toronto children\n",
    "section": "\n11.3 Data acquisition",
    "text": "11.3 Data acquisition\nSince we are looking at comparing census data over time, and census geographies change over time, we will rely on tongfen to harmonize the census geographies. As the base we will use census tracts. We can use the CensusMapper API GUI to select the vectors we need, the children under 15 in 2021 and the children under 15 in 2001, assembled from 5 year age groups for males and females.\n\nCodelibrary(tidyverse)\nlibrary(tongfen)\n\nmeta &lt;- meta_for_ca_census_vectors(c(children_2021=\"v_CA21_11\",\n                                     children1m_2001=\"v_CA01_7\",\n                                     children2m_2001=\"v_CA01_8\",\n                                     children3m_2001=\"v_CA01_9\",\n                                     children1f_2001=\"v_CA01_26\",\n                                     children2f_2001=\"v_CA01_27\",\n                                     children3f_2001=\"v_CA01_28\"))\n\n\nWe still need to get the region identifier for Toronto, either by using the CensusMapper API GUI or searching for it using the cancensus package.\n\nCodelibrary(cancensus)\nsearch_census_regions(\"Toronto\",\"CA21\")\n\n# A tibble: 3 × 8\n  region  name    level     pop municipal_status CMA_UID CD_UID PR_UID\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; \n1 35535   Toronto CMA   6202225 B                &lt;NA&gt;    &lt;NA&gt;   35    \n2 3520    Toronto CD    2794356 CDR              &lt;NA&gt;    &lt;NA&gt;   35    \n3 3520005 Toronto CSD   2794356 C                35535   3520   35    \n\n\nNow we have everything in place to get the data on a harmonized geography based on census tracts.\n\nCodetoronto_children &lt;- get_tongfen_ca_census(regions=list(CSD=\"3520005\"), meta=meta, \n                                          level = \"CT\", na.rm = TRUE)",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Toronto children</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/toronto_children.html#data-preparation",
    "href": "basic_descriptive/toronto_children.html#data-preparation",
    "title": "\n11  Toronto children\n",
    "section": "\n11.4 Data preparation",
    "text": "11.4 Data preparation\nThis time around we have a little bit of data preparation to do, we need to add up all the children from the age and gender groups for 2001.\n\nCodeplot_data &lt;- toronto_children |&gt;\n  mutate(children_2001=children1m_2001+children2m_2001+children3m_2001+\n           children1f_2001+children2f_2001+children3f_2001) |&gt;\n  select(matches(\"children_\\\\d{4}|Population\"))\n\n\nSometimes it can be tedious to spell out all the variables we want to add up, and we can use more abstract selections to specify what and how to add. In this case that’s complicated by also having geographic data attached, that we need to drop in order to perform row wise summation on our variables of interest. For reference, here is an alternative way to perform this summation that generalizes to more complex scenarios.\n\nCodeplot_data &lt;- toronto_children %&gt;%\n  mutate(children_2001=select(.,matches(\"children.+_2001\")) |&gt; \n           sf::st_drop_geometry() |&gt; \n           rowSums(na.rm=TRUE)) |&gt;\n  select(matches(\"children_\\\\d{4}|Population\"))",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Toronto children</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/toronto_children.html#analysis-and-visualization",
    "href": "basic_descriptive/toronto_children.html#analysis-and-visualization",
    "title": "\n11  Toronto children\n",
    "section": "\n11.5 Analysis and visualization",
    "text": "11.5 Analysis and visualization\nHere we need to simply map the difference in children.\n\nCodeggplot(plot_data, aes(fill=children_2021-children_2001)) +\n  geom_sf() +\n  scale_fill_gradient2(labels=scales::comma) +\n  coord_sf(datum=NA) +\n  labs(title=\"City of Toronto change in number of children under 15 between 2001 to 2021\",\n       fill=\"Number of\\nchildren\",\n       caption=\"StatCan Census 2001, 2021\")\n\n\n\n\n\n\n\nAnother view into this is to look at the change in the share of children in each region between these years.\n\nCodeggplot(plot_data, aes(fill=children_2021/Population_CA21-children_2001/Population_CA01)) +\n  geom_sf() +\n  scale_fill_gradient2(labels=scales::percent) +\n  coord_sf(datum=NA) +\n  labs(title=\"City of Toronto change in share of children under 15 between 2001 to 2021\",\n       fill=\"Percentage\\npoint\\nchange\",\n       caption=\"StatCan Census 2001, 2021\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Toronto children</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/toronto_children.html#interpretation",
    "href": "basic_descriptive/toronto_children.html#interpretation",
    "title": "\n11  Toronto children\n",
    "section": "\n11.6 Interpretation",
    "text": "11.6 Interpretation\nThe share of children has decreased in most areas, which is to be expected as Canada’s overall age distribution shifts with people living longer and baby boomers aging into the retirement age. This means that if we want to keep the other age groups, we need to make more space for them.\nLooking at the map with the absolute change in children we see that there are several areas where we did manage to make space for a shifting age distribution, and the total number of children increased even as their share decreased.\nAdditionally we see areas where not just the number but also the share of children increased. These are typically areas dominated by denser housing that traditionally weren’t attractive to families with children. But with increasing constraints on housing availability the only alternative is to commute into the city from increasingly longer distances, and living in family-sized apartments in the central parts is increasingly becoming an attractive alternative.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Toronto children</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html",
    "href": "basic_descriptive/number_of_household_maintainers.html",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "",
    "text": "12.1 Question\nIn a recent newspaper article it was reported that\nReading this we might be interested in more context.\nHow has the number of household maintainers changed in other municipalities, and what does this mean?",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#data-sources",
    "href": "basic_descriptive/number_of_household_maintainers.html#data-sources",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.2 Data sources",
    "text": "12.2 Data sources\nThe number of household maintainers is reported in the census:\n\nRefers to whether or not a person residing in the household is responsible for paying the rent, or the mortgage, or the taxes, or the electricity or other services or utilities. Where a number of people may contribute to the payments, more than one person in the household may be identified as a household maintainer. If no person in the household is identified as making such payments, the reference person is identified by default.\n\nThe census dictionary indicates that the ability to identify more than one household maintainer started with the 1996 census moving forward.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#data-acquisition",
    "href": "basic_descriptive/number_of_household_maintainers.html#data-acquisition",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.3 Data acquisition",
    "text": "12.3 Data acquisition\nWe need the tidyverse and cancensus packages,\n\nCodelibrary(tidyverse)\nlibrary(cancensus)\n\n\nand choose the appropriate census variables and decide what regions we are interested in. Moreover, we need to decide how long a timeframe we are interested in, the news article only referred to the 2016-2021 timeframe, but it might be worthwhile to also consider longer timeframes. The standard census profile data does not report on this before 2011 though, to keep things simple we collect data for the censuses 2011 and onward. We start by collecting the relevant census variables, labelled by base for the base number of households, and One, Two, and Three+ for 1, 2 or 3+ household maintainers.\n\nCodevectors &lt;- list(\n  \"2011\"=c(base=\"v_CA11N_2259\",One=\"v_CA11N_2260\",Two=\"v_CA11N_2261\",\"Three+\"=\"v_CA11N_2262\"),\n  \"2016\"=c(base=\"v_CA16_4873\",One=\"v_CA16_4874\",Two=\"v_CA16_4875\",\"Three+\"=\"v_CA16_4876\"),\n  \"2021\"=c(base=\"v_CA21_4275\",One=\"v_CA21_4276\",Two=\"v_CA21_4277\",\"Three+\"=\"v_CA21_4278\")\n)\n\n\nSelecting regions to compare Vancouver to is somewhat subjective. We go with a mix of larger cities in Metro Vancouver, as well as some from other provinces. One complication is that census geographies can change over time, so we need to be mindful of this. It is good practice to check this against the list of cities that changed 2011 to 2016 and 2016 to 2021, or explicitly inspect the geographies for changes.\nWe select from the list of all cities of at least 205k people (a number chosen to separate Richmond, BC from Richmond Hill, ON), and within that list narrow it down by matching by name.\n\nCoderegions &lt;- list_census_regions(\"CA21\") |&gt;\n  filter(level==\"CSD\",\n         pop&gt;205000,\n         grepl(\"Vancouver|Surrey|Burnaby|Richmond|Toronto|Calgary|Edmonton|Halifax|Winnipeg|Saskatoon|Montréal|Ottawa|Laval\",name))\n\nregions\n\n# A tibble: 13 × 8\n   region  name      level     pop municipal_status CMA_UID CD_UID PR_UID\n   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; \n 1 3520005 Toronto   CSD   2794356 C                35535   3520   35    \n 2 2466023 Montréal  CSD   1762949 V                24462   2466   24    \n 3 4806016 Calgary   CSD   1306784 CY               48825   4806   48    \n 4 3506008 Ottawa    CSD   1017449 CV               505     3506   35    \n 5 4811061 Edmonton  CSD   1010899 CY               48835   4811   48    \n 6 4611040 Winnipeg  CSD    749607 CY               46602   4611   46    \n 7 5915022 Vancouver CSD    662248 CY               59933   5915   59    \n 8 5915004 Surrey    CSD    568322 CY               59933   5915   59    \n 9 1209034 Halifax   CSD    439819 RGM              12205   1209   12    \n10 2465005 Laval     CSD    438366 V                24462   2465   24    \n11 4711066 Saskatoon CSD    266141 CY               47725   4711   47    \n12 5915025 Burnaby   CSD    249125 CY               59933   5915   59    \n13 5915015 Richmond  CSD    209937 CY               59933   5915   59    \n\n\nThis leaves us with 13 cities, and manual inspection shows that only Edmonton had a boundary change affecting population, resulting in a gain of 542 people 2016-2021. This should not make a noticeable difference for our analysis, so we will ignore this.\n\nCodemaintainer_data &lt;- bind_rows(\n  get_census(\"2011\",regions=as_census_region_list(regions), vectors=vectors[[\"2011\"]]) |&gt;\n    mutate(Year=\"2011\"),\n  get_census(\"2016\",regions=as_census_region_list(regions), vectors=vectors[[\"2016\"]]) |&gt;\n    mutate(Year=\"2016\"),\n  get_census(\"2021\",regions=as_census_region_list(regions), vectors=vectors[[\"2021\"]]) |&gt;\n    mutate(Year=\"2021\")\n) |&gt;\n  select(GeoUID,Year,base,One,Two,`Three+`) |&gt;\n  left_join(regions |&gt; select(GeoUID=region,Name=name),by=\"GeoUID\")\n\n\nGetting the data for the three censuses and our selection of regions is easy, we join on the region names to make sure we have a uniform way to format and spell the names.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#data-preparation",
    "href": "basic_descriptive/number_of_household_maintainers.html#data-preparation",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.4 Data preparation",
    "text": "12.4 Data preparation\nWe are interested in shares rather than absolute numbers, for this we change the three different maintainer categories to long form and compute shares.\n\nCodemaintainer_levels &lt;- c(\"One\",\"Two\",\"Three+\")\nplot_data &lt;- maintainer_data |&gt;\n  pivot_longer(maintainer_levels, names_to=\"Maintainers\",values_to = \"Value\") |&gt;\n  mutate(Share=Value/base)",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#analysis-and-visualization",
    "href": "basic_descriptive/number_of_household_maintainers.html#analysis-and-visualization",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.5 Analysis and visualization",
    "text": "12.5 Analysis and visualization\nTo visualize the data it can be useful to be deliberate about the order of variables. In R we preferably use factors to deal with categorical data, and the factor levels can be set to fix their order in visualizations.\n\nCodename_order &lt;- plot_data |&gt;\n  filter(Year==\"2021\",Maintainers==\"One\") |&gt; \n  arrange(Value) |&gt; \n  pull(Name)\n  \nplot_data &lt;- plot_data |&gt; \n  mutate(Name=factor(Name,name_order)) |&gt;\n  mutate(Maintainers=factor(Maintainers, levels = maintainer_levels))\n\n\nWith that in place we can plot the data. We are in particular interested in the change from 2016 to 2021, so we add in an arrow to emphasize this.\n\nCodeplot_data |&gt;\n  select(Name,Year,Maintainers,Share) |&gt;\nggplot(aes(y=Name, x=Share)) + \n  geom_point(aes(colour=Year)) +\n  scale_colour_manual(values=sanzo::trios$c157)  +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~Maintainers,scales=\"free_x\") +\n  geom_segment(data=~pivot_wider(.,names_from = Year,values_from = Share),\n               aes(x=`2016`,xend=`2021`,yend=Name),\n               arrow = arrow(length = unit(0.1,\"inches\"))) +\n  scale_x_continuous(labels=scales::percent) +\n  labs(title=\"Number of household maintainers by municipality\",\n       y=NULL,x=\"Share of households by number of household maintainers\",\n       colour=NULL,\n       caption=\"StatCan Census 2021, 2016\")\n\n\n\n\n\n\n\nTo add the segments we took the plot data and pivoted it wider by Year, allowing us to select the start and endpoints for our arrows indicating the movement 2016 to 2021.\nLooking at the graph for 2011 to 2016 we notice a general decrease in the share of one-person maintainer households, coupled with an increase in both two and three-person maintainer households. But this trend is not uniform and is at least partially reversed for some cities, for example Saskatoon or Halifax. But for 2016 to 2021 the trends are very large and uniform. To the extend that one gets suspicious, demographic changes usually happen gradually and don’t show strong across the board changes like this. Either something big has happened, or we have some data issues.\nAt this point we should go back a step and try to understand what is going on here.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#analysis-revisited",
    "href": "basic_descriptive/number_of_household_maintainers.html#analysis-revisited",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.6 Analysis (revisited)",
    "text": "12.6 Analysis (revisited)\nLet’s try and understand what processes could be driving differences or changes in the number of household maintainers. Household size is a large factor, one person households can have at most one household maintainer. Similarly, a two-person household can have at most two household maintainers. We can try to filter some of this effect out by looking only at two or more person households, that might give a clearer picture of what is going on.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#data-acquisition-revisited",
    "href": "basic_descriptive/number_of_household_maintainers.html#data-acquisition-revisited",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.7 Data acquisition (revisited)",
    "text": "12.7 Data acquisition (revisited)\nFor this we need data on the number of one-person households for the three years. The process is easily adapted from the code above.\n\nCodevectors2 &lt;- list(\n  \"2011\"=c(`One person households`=\"v_CA11F_210\"),\n  \"2016\"=c(`One person households`=\"v_CA16_419\"),\n  \"2021\"=c(`One person households`=\"v_CA21_444\")\n)\n\nhousehold_size_data &lt;- bind_rows(\n  get_census(\"2011\",regions=as_census_region_list(regions), vectors=vectors2[[\"2011\"]]) |&gt;\n    mutate(Year=\"2011\"),\n  get_census(\"2016\",regions=as_census_region_list(regions), vectors=vectors2[[\"2016\"]]) |&gt;\n    mutate(Year=\"2016\"),\n  get_census(\"2021\",regions=as_census_region_list(regions), vectors=vectors2[[\"2021\"]]) |&gt;\n    mutate(Year=\"2021\")\n) |&gt;\n  select(GeoUID,Year,`One person households`) \n\n\nNow we need to combine the data on household maintainers with the data on one-person households, which we do by joining the data frames by geographic identifier and year. Then we subtract out one-person households from the denominator and the numerator of single maintainer households, and proceed as before.\n\nCodeplot_data2 &lt;- maintainer_data |&gt;\n  full_join(household_size_data,by=c(\"GeoUID\",\"Year\")) |&gt;\n  mutate(base=base-`One person households`,\n         `One`=`One`-`One person households`) |&gt;\n  pivot_longer(maintainer_levels, names_to=\"Maintainers\",values_to = \"Value\") |&gt;\n  mutate(Share=Value/base) %&gt;%\n  mutate(Name=factor(Name,filter(.,Year==\"2021\",Maintainers==\"One\") |&gt; \n                       arrange(Value) |&gt; \n                       pull(Name))) |&gt; \n  mutate(Maintainers=factor(Maintainers, levels = maintainer_levels))",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#visualization-revisited",
    "href": "basic_descriptive/number_of_household_maintainers.html#visualization-revisited",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.8 Visualization (revisited)",
    "text": "12.8 Visualization (revisited)\nFor visualization we copy the code from before and add in a subtitle to indicate that we excluded one-person households.\n\nCodeplot_data2 |&gt;\n  select(Name,Year,Maintainers,Share) |&gt;\nggplot(aes(y=Name, x=Share)) + \n  geom_point(aes(colour=Year)) +\n  scale_colour_manual(values=sanzo::trios$c157)  +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~Maintainers,scales=\"free_x\") +\n  geom_segment(data=~pivot_wider(.,names_from = Year,values_from = Share),\n               aes(x=`2016`,xend=`2021`,yend=Name),\n               arrow = arrow(length = unit(0.1,\"inches\"))) +\n  scale_x_continuous(labels=scales::percent) +\n  labs(title=\"Number of household maintainers by municipality\",\n       subtitle=\"Excluding one-person households\",\n       y=NULL,x=\"Share of households by number of household maintainers\",\n       colour=NULL,\n       caption=\"StatCan Census 2021, 2016\")\n\n\n\n\n\n\n\nDropping one-person households does remove some of the variation between cities, but it amplifies the effect of the drop in single maintainer households 2016-2021, while the change for 2011-2016 is still ambiguous, although in most cases also dropping. It’s hard to imagine what processes could cause such large change across all these cities. Shifting demographics, like Millennials aging into family formation years and coupling up could have some effect, but not of this magnitude. Changes in housing affordability, and people coupling or tripling up to pay for housing could also cause some shift, but these kind of shifts happen more gradually and won’t affect such a large share of households.\nThis is a bit of a puzzle, time to dig a little deeper at the data sources.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#data-sources-revisited",
    "href": "basic_descriptive/number_of_household_maintainers.html#data-sources-revisited",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.9 Data sources (revisited)",
    "text": "12.9 Data sources (revisited)\nWe have looked through the census dictionary and found no indication that the concept of the number of household maintainers changed over our time period, with a minor caveat that 2011 data is from the voluntary National Household Survey instead of the mandatory long form census.\nBut the Housing Characteristics Reference Guide shows that StatCan flagged this issue of lack of ability to compare this concept over time. They write:\n\nIn 2021, the household maintainer question was asked for every member of the household aged 15 years or older. Previously, in 2016, the question had a mark-all-that-apply format for the first five persons listed on the paper questionnaire. This alteration to the paper questionnaire brings better visual resemblance between the electronic and paper questionnaires. The wording was also modified to include a qualifying statement of “partly or entirely” when referring to the payments. The result of these changes is the capture of more household maintainers who are not the primary household maintainer. \nThe growth rate of the number of primary household maintainers since the 2016 Census of Population was 6.4%, the same as the growth rate of private occupied dwellings, because every private occupied dwelling has one primary maintainer. At the same time, the growth rate of other household maintainers over the same period was 34.1%, indicating more comprehensive coverage of all household maintainers. This has not affected the characteristics of the primary household maintainer, which are often used to derive statistics such as the homeownership rates of different generations. However, the more complete coverage of other maintainers will allow for future analysis of the characteristics of these other household members contributing to housing payments.\n\nWe can track this further by looking at the 2011 NHS and 2016 census questionnaires, where the information on the number of household maintainers comes from the first question on the dwelling section, Question E1 and F1, respectively.\nIn the 2011 NHS the question reads:\n\nE1 Who pays the rent or mortgage, taxes, electricity, etc., for this dwelling?\n\n1: Person 1\n2: Person 2\n3: Person 3\n4: Person 4\n5: Person 5\n6: A person who is listed on another questionnaire for this dwelling\n7: A person who does not live here\n\n\nIn the 2016 census the question reads identical, except it received an additional instruction on how to answer if more than one person contributes.\n\nF1. Who pays the rent or mortgage, taxes, electricity, etc., for this dwelling?\nIf more than one person contributes to such payments, mark as many circles as apply.\n\n1: Person 1\n2: Person 2\n3: Person 3\n4: Person 4\n5: Person 5\n6: A person who is listed on another questionnaire for this dwelling\n7: A person who does not live here\n\n\nThis change in instruction could impact how people answer this question, plausibly increasing the number of people listing multiple people as household maintainers. This taints the overall drop in single household maintainers that we observed in the data 2011-2016.\nFor the 2021 census the question on household maintainers has been removed from the dwelling section and added to the section that is to be separately filled out for every person in the household. It is not question 58 of part D, which reads.\n\n58. Does this person pay, partly or entirely, the rent or mortgage, taxes, electricity, etc. for this dwelling?\nMark “Yes” if this person pays the rent or mortgage, taxes, electricity, etc. for this dwelling, even if more than one person contributes to such payments.\nA dwelling is a separate set of living quarters with a private entrance from the outside or from a common hallway or stairway inside the building. This entrance should not be through someone else’s living quarters.\nDo not consider payments for other dwellings such as the school residence of a child, the residence of a former spouse, or another dwelling that you may own or rent.\n\nYes\nNo",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/number_of_household_maintainers.html#interpretation",
    "href": "basic_descriptive/number_of_household_maintainers.html#interpretation",
    "title": "\n12  Number of Household Maintainers\n",
    "section": "\n12.10 Interpretation",
    "text": "12.10 Interpretation\nThe number of household maintainer variable is not comparable across the 2016 to 2021 censuses, and may also be somewhat tainted for comparisons 2011 to 2016. We observe large changes in the shares of single and multiple household maintainer households 2016 to 2021 that are very likely dominated by changes to the census questionnaire.\nComparisons across regions for fixed years can still be informative, with data prior to 2021 likely being tainted by people misreading the question and selecting only one household maintainer where they should have selected more than one. Composition of households by household size also matter, removing one-person household when computing shares can remove some of the bias introduced by some municipalities having a significantly higher share of one-person households than others. This effect is particularly strong when comparing Vancouver and Surrey.\nIt would be worthwhile to look deeper into what drives three or more household maintainer households, either using cross tabulations or PUMF data. Surrey’s high share of multigenerational households is a likely contributor to Surrey’s high share of three or more household maintainer households.\nThis exercise serves as a good reminder to be suspicious of implausibly large effects in data. Most probably these arise as a result of errors in the data analysis process, but may also come about due to changes in definitions or in the data generation process, in this case the questionnaire.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Number of Household Maintainers</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/land_values.html",
    "href": "basic_descriptive/land_values.html",
    "title": "\n13  Land and building values\n",
    "section": "",
    "text": "13.1 Question\nThe Globe and Mail reported that\nTo anyone familiar with Vancouver during this time frame the claim that “building values stayed the same” seems questionable. This brings us to our question.\nHow have land and building values in Vancouver changed since 2005 (2006 tax assessment year)?",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Land and building values</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/land_values.html#data-sources",
    "href": "basic_descriptive/land_values.html#data-sources",
    "title": "\n13  Land and building values\n",
    "section": "\n13.2 Data sources",
    "text": "13.2 Data sources\nLand and building values are assessed separately by BC Assessment, and we will piggy-back of their estimates instead of trying to estimate them ourselves. The City of Vancouver makes assessment data for the City available on their Open Data Portal.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Land and building values</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/land_values.html#data-acquisition",
    "href": "basic_descriptive/land_values.html#data-acquisition",
    "title": "\n13  Land and building values\n",
    "section": "\n13.3 Data acquisition",
    "text": "13.3 Data acquisition\nThe VanouvR package (“VancouvR: Access the ’City of Vancouver’ Open Data API” 2019) makes it easy to access this data in R and one of the package vignettes has code that does pretty much what we need.\n\nCodelibrary(tidyverse)\nlibrary(VancouvR)\n\n\nThe datasets in question are the property-tax-report, due to size the data is split over several datasets.\n\nCodesearch_cov_datasets(\"property-tax-report\") |&gt;\n  select(dataset_id,title)\n\n# A tibble: 4 × 2\n  dataset_id                    title                        \n  &lt;chr&gt;                         &lt;chr&gt;                        \n1 property-tax-report-2016-2019 Property tax report 2016-2019\n2 property-tax-report-2011-2015 Property tax report 2011-2015\n3 property-tax-report           Property tax report          \n4 property-tax-report-2006-2010 Property tax report 2006-2010\n\n\nThe first tax assessment year in the dataset is for 2006, the last one is for the current year, 2024 as of the writing of this. Assessments are pegged to July 1st of the previous year, so we have data for all years from July 2005 through 2023. This is likely the same data source that news article used, except that the article did not adjust to the date the assessments are pegged to.\nFor our purposes all we need is aggregates for each year, the Open Data Portal allows server side aggregation of data and the R package supports that. This cuts down on time and the amount of data we need to transfer. We simply group by tax assessment year and aggregate up the assessed land and building values for each year.\n\nCodeland_building_data_raw &lt;-search_cov_datasets(\"property-tax-report\") |&gt;\n    pull(dataset_id) |&gt;\n    map_df(function(ds) aggregate_cov_data(\n      ds,\n      group_by=\"tax_assessment_year as Year\",\n      select=\"sum(current_land_value) as Land, sum(current_improvement_value) as Building\")) |&gt;\n  arrange(Year)\n\n\nThis gives us a simple data frame with land and building values for each year. We check on the tax years in question, as well as the most recent one.\n\nCodeland_building_data_raw |&gt; \n  filter(Year %in% c(2006,2022,max(Year))) |&gt;\n  tinytable::tt()\n\n \n\n  \n    \n\ntinytable_g4czbshrgb8xdyctrsll\n\n\n      \n\nYear\n                Land\n                Building\n              \n\n\n2006\n                   88649668277\n                   35086836003\n                \n\n2022\n                  394201892132\n                  102591491465\n                \n\n2024\n                  415679362031\n                  105858810250",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Land and building values</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/land_values.html#data-preparation",
    "href": "basic_descriptive/land_values.html#data-preparation",
    "title": "\n13  Land and building values\n",
    "section": "\n13.4 Data preparation",
    "text": "13.4 Data preparation\nThere is not much to do here, we remember that assessments are pegged to July 1st in the previous year and reshape the data into long form.\n\nCodeland_building_data &lt;- land_building_data_raw |&gt;\n    mutate(Date=as.Date(paste0(as.integer(Year)-1,\"-07-01\"))) |&gt;\n    pivot_longer(c(\"Land\",\"Building\"),names_to = \"Component\")",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Land and building values</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/land_values.html#analysis-and-visualization",
    "href": "basic_descriptive/land_values.html#analysis-and-visualization",
    "title": "\n13  Land and building values\n",
    "section": "\n13.5 Analysis and visualization",
    "text": "13.5 Analysis and visualization\nLet’s take a quick look what that data looks like.\n\nCodeggplot(land_building_data,aes(x=Date,y=value,colour=Component)) +\n  geom_line() +\n  scale_y_continuous(labels=\\(x)scales::dollar(x,scale=10^-9,suffix=\"bn\")) +\n  expand_limits(y=0) +\n  labs(title=\"City of Vancouver assessed land and building values\",\n       y=\"Assessed value\",\n       x=NULL,\n       caption=\"CoV Open Data\")\n\n\n\n\n\n\nFigure 13.1\n\n\n\n\nSo far so good, but we should probably account for inflation. We borrow code from the section on income change to pull CPI data and fold it in.\n\nCodelibrary(cansim)\ninflation &lt;- get_cansim_vector(\"v41693271\") |&gt;\n  mutate(Date=Date %m+% months(6)) |&gt;\n  select(Date,CPI=val_norm) |&gt;\n  filter(Date %in% land_building_data$Date) |&gt;\n  mutate(CPI=CPI/last(CPI,order_by = Date))\n\nland_building_data |&gt;\n  left_join(inflation,by=\"Date\") |&gt;\nggplot(aes(x=Date,y=value/CPI,colour=Component)) +\n  geom_line() +\n  scale_y_continuous(labels=\\(x)scales::dollar(x,scale=10^-9,suffix=\"bn\")) +\n  expand_limits(y=0) +\n  labs(title=\"City of Vancouver assessed land and building values\",\n       y=\"Assessed value (July 2023 dollars)\",\n       x=NULL,\n       caption=\"CoV Open Data\")\n\n\n\n\n\n\nFigure 13.2\n\n\n\n\nAs we might have expected, values rose faster than inflation, but they did so for buildings as well as for land. The land value change is impressive, but it’s hard to judge that against the building value change, which started at a much lower value. The article looked at percentage change, so let’s do the same.\n\nCodeplot_data &lt;- land_building_data |&gt;\n  left_join(inflation,by=\"Date\") |&gt;\n  mutate(real_value=value/CPI) |&gt;\n  mutate(real_ratio = real_value/first(real_value,order_by=Date),\n         ratio = value/first(value,order_by=Date),\n         .by=Component)\n\nggplot(plot_data,aes(x=Date,y=real_ratio,colour=Component)) +\n  geom_line() +\n  scale_y_continuous(labels=\\(x)scales::percent(x-1),\n                     trans=\"log\",breaks=seq(1,5)) +\n  labs(title=\"City of Vancouver assessed land and building values\",\n       y=\"Real change since July 1, 2005\",\n       x=NULL,\n       caption=\"CoV Open Data\")\n\n\n\n\n\n\nFigure 13.3\n\n\n\n\nSince this is ratio data we chose a logarithmic scale on the y-axis. This shows that between 2005 and 2021 (so using assessment years 2006 and 2022) real land values increased by 236% and building values by 121% . Maybe the article was using nominal value increases, in nominal terms land increased by 345% and building values by 192%.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Land and building values</span>"
    ]
  },
  {
    "objectID": "basic_descriptive/land_values.html#interpretation",
    "href": "basic_descriptive/land_values.html#interpretation",
    "title": "\n13  Land and building values\n",
    "section": "\n13.6 Interpretation",
    "text": "13.6 Interpretation\nThe increase in land values is lower than the “more than 500 per cent” claimed in the article, and the claim that “building values stayed the same” is clearly false.\nWhat is clear is that land values have risen faster than building values, likely in large part because restrictive zoning has prevented buildings from making adequate use of the land they are on.\nIt could be that the article mis-quoted its sources and the claim was about a sub-set of Vancouver properties, maybe just residential properties, or just single-family properties. We make a rather crude estimate by filtering the data on RS-1 and R1-1 zoning districts. This will under-estimate the growth a bit as properties that got rezoned within this timeframe will be included in the earlier years but not in the later ones.\n\nCodesearch_cov_datasets(\"property-tax-report\") |&gt;\n    pull(dataset_id) |&gt;\n    map_df(function(ds) aggregate_cov_data(\n      ds,\n      group_by=\"tax_assessment_year as Year\",\n      where=\"zoning_district like 'RS-' or zoning_district like 'R1-1'\",\n      select=\"sum(current_land_value) as Land, sum(current_improvement_value) as Building\")) %&gt;% \n    mutate(Date=as.Date(paste0(as.integer(Year)-1,\"-07-01\"))) |&gt;\n    pivot_longer(c(\"Land\",\"Building\"),names_to = \"Component\") |&gt;\n  left_join(inflation,by=\"Date\") |&gt;\n  mutate(real_value=value/CPI) |&gt;\n  mutate(real_ratio = real_value/first(real_value,order_by=Date),\n         ratio = value/first(value,order_by=Date),\n         .by=Component) |&gt;\nggplot(aes(x=Date,y=real_ratio,colour=Component)) +\n  geom_line() +\n  scale_y_continuous(labels=\\(x)scales::percent(x-1),,\n                     trans=\"log\",breaks=seq(1,5)) +\n  expand_limits(y=0) +\n  labs(title=\"City of Vancouver assessed land and building values in RS/R1-1 zones\",\n       y=\"Real change since July 1, 2005\",\n       x=NULL,\n       caption=\"CoV Open Data\")\n\n\n\n\n\n\nFigure 13.4\n\n\n\n\nAgain, the claim that building values stayed the same has no basis in reality. Readers interested in more detail are encouraged to use individual property data and match individual lots over time to further refine these estimates.\n\n\n\n\n\n\n“VancouvR: Access the ’City of Vancouver’ Open Data API.” 2019. The R Foundation. https://doi.org/10.32614/cran.package.vancouvr.",
    "crumbs": [
      "Basic descriptive analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Land and building values</span>"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive.html",
    "href": "advanced_descriptive/advanced_descriptive.html",
    "title": "Advanced descriptive analysis",
    "section": "",
    "text": "Building on the section of basic descriptive analysis we will move into more advanced data processing and descriptive analysis. This will involve mixing of different datasets to tease out finer aspects. We will learn how to group and summarize data, and how to use joins.",
    "crumbs": [
      "Advanced descriptive analysis"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive_bc_migration.html",
    "href": "advanced_descriptive/advanced_descriptive_bc_migration.html",
    "title": "\n14  BC migration\n",
    "section": "",
    "text": "14.1 Question\nThis example is motivated by a BC government press release titled “B.C. welcomes more than 100,000 people – the most in 60 years”. This is the type of attention-grabbing headline where our gut reaction usually is to question if this is true.\nLet’s first try and understand what the headline really means. B.C. “welcoming” people refers to people moving to the province from elsewhere, either from other provinces or internationally. So this is referring to gross in-migration. But reading the text of the press release it immediately pivots to a different concept, saying that “B.C.’s net migration reached 100,797 people in 2021”. It helpfully explains that net migration is the difference between people moving here and people moving away. Which is quite different from the number of people B.C. “welcomed” that year, or the number of people “moving to the province in 2021” as implied by the title and the first sentence of the press release.\nSo here comes the first difficulty, the press release is contradicting itself by mixing two concepts. That leads us to formulate a fairly broad question that should help clear this up.\nHow many people has B.C. welcomed, net and gross, how has that changed over the last 6 decades, and how should this be interpreted?",
    "crumbs": [
      "Advanced descriptive analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>BC migration</span>"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive_bc_migration.html#data-sources",
    "href": "advanced_descriptive/advanced_descriptive_bc_migration.html#data-sources",
    "title": "\n14  BC migration\n",
    "section": "\n14.2 Data sources",
    "text": "14.2 Data sources\nTo start, let’s figure out where that data point comes from.\nThe press release references StatCan as the source, let’s search through the StatCan tables. Google usually works reasonably well, but we can also search programmatically. We are looking for migration estimates from the quarterly demographic estimates to get the most up-to-data population estimates from StatCan. For results we just need the first two columns, that table number and the title.\n\nCodelibrary(tidyverse)\nlibrary(cansim)\n\nsearch_cansim_cubes(\"migration\") |&gt; \n  filter(grepl(\"quarterly\",cubeTitleEn)) |&gt;\n  arrange(desc(cubeEndDate)) |&gt; \n  select(1:2)\n\n# A tibble: 2 × 2\n  cansim_table_number cubeTitleEn                                               \n  &lt;chr&gt;               &lt;chr&gt;                                                     \n1 17-10-0020          Estimates of the components of interprovincial migration,…\n2 17-10-0040          Estimates of the components of international migration, q…\n\n\nIt looks like Table 17-10-0020 and 17-10-0040 are what we are looking for. Let’s load in the data and inspect the first couple of rows for BC.",
    "crumbs": [
      "Advanced descriptive analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>BC migration</span>"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive_bc_migration.html#data-acquisition",
    "href": "advanced_descriptive/advanced_descriptive_bc_migration.html#data-acquisition",
    "title": "\n14  BC migration\n",
    "section": "\n14.3 Data acquisition",
    "text": "14.3 Data acquisition\n\nCodeinterprovincial &lt;- get_cansim(\"17-10-0020\")\ninternational &lt;- get_cansim(\"17-10-0040\")\n\ninterprovincial |&gt;\n  filter(GEO==\"British Columbia\") |&gt;\n  select(GEO,Date,`Interprovincial migration`,val_norm) |&gt;\n  tail()\n\n# A tibble: 6 × 4\n  GEO              Date       `Interprovincial migration` val_norm\n  &lt;chr&gt;            &lt;date&gt;     &lt;fct&gt;                          &lt;dbl&gt;\n1 British Columbia 2023-04-01 In-migrants                    22371\n2 British Columbia 2023-04-01 Out-migrants                   22671\n3 British Columbia 2023-07-01 In-migrants                    12552\n4 British Columbia 2023-07-01 Out-migrants                   17186\n5 British Columbia 2023-10-01 In-migrants                     7892\n6 British Columbia 2023-10-01 Out-migrants                   10620\n\n\nFor inter-provincial migration we get in and out migration counts for every quarter. Let’s also inspect the international migration data.\n\nCodeinternational |&gt;\n  filter(GEO==\"British Columbia\") |&gt;\n  select(GEO,Date,`Components of population growth`,val_norm) |&gt;\n  tail()\n\n# A tibble: 6 × 4\n  GEO              Date       `Components of population growth` val_norm\n  &lt;chr&gt;            &lt;date&gt;     &lt;fct&gt;                                &lt;dbl&gt;\n1 British Columbia 2023-10-01 Net emigration                        2890\n2 British Columbia 2023-10-01 Emigrants                             4853\n3 British Columbia 2023-10-01 Returning emigrants                   1963\n4 British Columbia 2023-10-01 Net non-permanent residents          20516\n5 British Columbia 2023-10-01 Non-permanent residents, inflows     54008\n6 British Columbia 2023-10-01 Non-permanent residents, outflows    33492\n\n\nHere we get immigrants, emigrants, returning emigrants, but for temporary emigrants and non-permanent residents we only get net change. That puts a bit of a damper on our ambition to look at gross migration, for those last two categories net is all we have.",
    "crumbs": [
      "Advanced descriptive analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>BC migration</span>"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive_bc_migration.html#data-preparation",
    "href": "advanced_descriptive/advanced_descriptive_bc_migration.html#data-preparation",
    "title": "\n14  BC migration\n",
    "section": "\n14.4 Data preparation",
    "text": "14.4 Data preparation\nNext we got to wrangle this data into a useful format. We are interested in all of these components, so we need to join these two data series together. We will retain the GeoUID, GEO, Components of population growth, Date and val_norm columns, which requires some renaming and then defining factor levels so that they stack nicely later in our plots. We also flip the sign on out-migrants and emigrants, as these are out-flows. To make sure those two time series start at the same time we cut it off appropriately.\nThe press release talked about annual change, so we do a rolling sum over 4 quarters, right-aligning the data so it’s for the period of the preceding year.\n\nCodemigration_data &lt;- bind_rows(\n  interprovincial |&gt; \n    select(GeoUID,GEO,Date,\n           `Components of population growth`=`Interprovincial migration`,val_norm) |&gt;\n    mutate(`Components of population growth`=\n             paste0(\"Interprovincial \",tolower(`Components of population growth`))),\n  international |&gt; \n    select(GeoUID,GEO,Date,`Components of population growth`,val_norm)\n) |&gt;\n  mutate(`Components of population growth`=\n           factor(`Components of population growth`,\n                  levels=c(\"Interprovincial out-migrants\",\n                           \"Emigrants\",\n                           \"Interprovincial in-migrants\",\n                           \"Immigrants\",\n                           \"Returning emigrants\",\n                           \"Net temporary emigrants\",\n                           \"Net non-permanent residents\"))) |&gt;\n  mutate(value=ifelse(`Components of population growth` %in% \n                        c(\"Interprovincial out-migrants\",\"Emigrants\"),\n                      -val_norm,val_norm)) |&gt;\n  filter(Date&gt;=pmax(min(interprovincial$Date),min(international$Date))) |&gt;\n  group_by(GeoUID,`Components of population growth`) |&gt;\n  arrange(Date) |&gt;\n  mutate(annual=zoo::rollsum(value,k=4,na.pad = TRUE,align = \"right\")) |&gt;\n  filter(!is.na(annual)) |&gt;\n  ungroup()\n\n\nWe will also need net migration stats, so let’s compute these by summing of the components,\n\nCodenet_migration &lt;- migration_data |&gt; \n  group_by(Date,GEO,GeoUID) |&gt;\n  summarize(value=sum(value),annual=sum(annual),.groups=\"drop\") |&gt;\n  mutate(`Components of population growth`=\"Net migration\")",
    "crumbs": [
      "Advanced descriptive analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>BC migration</span>"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive_bc_migration.html#analysis-and-visualization",
    "href": "advanced_descriptive/advanced_descriptive_bc_migration.html#analysis-and-visualization",
    "title": "\n14  BC migration\n",
    "section": "\n14.5 Analysis and visualization",
    "text": "14.5 Analysis and visualization\nTime to make a graph.\n\nCodemigration_colours &lt;- setNames(MetBrewer::met.brewer(\"Archambault\",7),\n                              migration_data$`Components of population growth` %&gt;% \n                                levels %&gt;% rev)\n\nggplot(migration_data |&gt; filter(GEO==\"British Columbia\")) +\n  geom_area(aes(x=Date,y=annual,fill=fct_rev(`Components of population growth`)),\n           stat=\"identity\") +\n  scale_y_continuous(labels=scales::comma) +\n  geom_line(data=net_migration |&gt; filter(GEO==\"British Columbia\"),\n            aes(x=Date,y=annual)) +\n  scale_fill_manual(values=migration_colours) +\n  labs(title=\"BC Year over year migration\",\n       y=\"Year over year change\",x=NULL,fill=\"Components of population change\",\n       caption=\"StatCan Tables 17-10-0020, 17-10-0040\")\n\n\n\n\n\n\n\nThis shows us that the press report did not mean to talk about number of people B.C. has “welcomed” or that “moved to the province” but instead the difference between the number of people it welcomed and the number of people it bid farewell.\nAnd the net migration is indeed at record levels. At least in absolute terms. But B.C. now is very different from B.C. in the 60s at the start of this time series. How can we compare net migration over time in a more meaningful way? Normalizing by population is a good option here. Let’s grab the data and take a look how B.C. population has changed.\n\nCodepop_data &lt;- get_cansim(\"17-10-0009\") |&gt;\n  select(GEO,Date,Population=val_norm)\n\npop_data |&gt; \n  filter(GEO==\"British Columbia\") |&gt;\n  ggplot(aes(x=Date,y=Population)) +\n  geom_line() +\n  scale_y_continuous(labels=scales::comma) +\n  labs(title=\"Population estimates for British Columbia\",\n       y=\"Number of people\",\n       x=NULL,\n       caption=\"StatCan Table 17-10-0009\")\n\n\n\n\n\n\n\nIndeed, the trend is quite strong. Let’s fold that in and normalize by population.\n\nCodemigration_data |&gt; \n  left_join(pop_data, by=c(\"GEO\",\"Date\")) |&gt;\n  filter(GEO==\"British Columbia\") |&gt;\n  ggplot() +\n  geom_area(aes(x=Date,y=annual/Population,fill=fct_rev(`Components of population growth`)),\n           stat=\"identity\") +\n  scale_y_continuous(labels=scales::percent) +\n  geom_line(data=net_migration |&gt; \n              left_join(pop_data, by=c(\"GEO\",\"Date\")) |&gt;\n              filter(GEO==\"British Columbia\"),\n            aes(x=Date,y=annual/Population)) +\n  scale_fill_manual(values=migration_colours) +\n  labs(title=\"BC Year over year migration\",\n       y=\"Year over year change per population\",x=NULL,\n       fill=\"Components of population change\",\n       caption=\"StatCan Tables 17-10-0020, 17-10-0040, 17-10-0009\")\n\n\n\n\n\n\n\nHere the picture looks a little different. Net migration per capita is at its highest since the 90s, but the past 60 years there were several periods where it was larger.\nThe press report also mentioned that B.C.’s interprovincial migration numbers are higher than any other province. This is easy to check now. In line with the press release that prompted our question we are pinning the data at the forth quarter of 2021.\n\nCodepinned_date &lt;- as.Date(\"2021-10-01\")\n\n\n\nCodemigration_data_interprovinicial &lt;- migration_data |&gt;\n  left_join(pop_data, by=c(\"GEO\",\"Date\")) |&gt;\n  filter(grepl(\"Interprovincial\",`Components of population growth`))\n\nnet_interprovincial &lt;- migration_data_interprovinicial |&gt;\n  group_by(GEO,Date) |&gt;\n  summarize(value=sum(value),\n            annual=sum(annual),\n            Population=first(Population),\n            .groups=\"drop\")\n\nmigration_data_interprovinicial |&gt; \n  filter(GEO!=\"Canada\") |&gt;\n  filter(Date==pinned_date) |&gt;\n  ggplot(aes(y=GEO,x=annual)) +\n  geom_bar(stat=\"identity\",\n           aes(fill=fct_rev(`Components of population growth`))) +\n  geom_boxplot(data=net_interprovincial |&gt; \n                 filter(GEO!=\"Canada\") |&gt;\n                 filter(Date==max(Date))) +\n  scale_fill_manual(values=migration_colours[grepl(\"Interprov\",names(migration_colours))]) +\n  scale_x_continuous(labels=scales::comma) +\n  labs(title=\"Interprovincial migration Q4 2020 to Q4 2021\",\n       fill=\"Components of population growth\",\n       y=NULL,x=\"Year over year change\",\n       caption=\"StatCan Tables 17-10-0020, 17-10-0040, 17-10-0009\")\n\n\n\n\n\n\n\nIn absolute number B.C. indeed has both the highest interprovincial in-migration and interprovincial net-migration among all provinces. But the provinces have vastly different sizes, so that’s not really a fair comparison. Again, we can normalize by population.\n\nCodemigration_data_interprovinicial |&gt; \n  filter(GEO!=\"Canada\") |&gt;\n  filter(Date==pinned_date) |&gt;\n  ggplot(aes(y=GEO,x=annual/Population)) +\n  geom_bar(stat=\"identity\",\n           aes(fill=fct_rev(`Components of population growth`))) +\n  geom_boxplot(data=net_interprovincial |&gt; \n                 filter(GEO!=\"Canada\") |&gt;\n                 filter(Date==max(Date))) +\n  scale_fill_manual(values=migration_colours[grepl(\"Interprov\",names(migration_colours))]) +\n  scale_x_continuous(labels=scales::percent) +\n  labs(title=\"Interprovincial migration Q4 2020 to Q4 2021\",\n       fill=\"Components of population growth\",\n       y=NULL,x=\"Year over year change per capita\",\n       caption=\"StatCan Tables 17-10-0020, 17-10-0040, 17-10-0009\")\n\n\n\n\n\n\n\nViewed this way B.C.’s interprovincial in-migration and net migration still looks good, but many of the other provinces beat out that growth rate.\nFor completeness we can also just show the full graph that includes the international migration components.\n\nCodemigration_data |&gt; \n  left_join(pop_data, by=c(\"GEO\",\"Date\")) |&gt;\n  filter(Date==pinned_date) |&gt;\n  ggplot(aes(y=GEO,x=annual/Population)) +\n  geom_bar(stat=\"identity\",aes(fill=fct_rev(`Components of population growth`))) +\n  geom_boxplot(data=net_migration |&gt; \n                 left_join(pop_data, by=c(\"GEO\",\"Date\")) |&gt; \n                 filter(Date==max(Date))) +\n  scale_fill_manual(values=migration_colours) +\n  scale_x_continuous(labels=scales::percent) +\n  labs(title=\"Migration Q4 2020 to Q4 2021\",\n       fill=\"Components of population growth\",\n       y=NULL,x=\"Year over year change per capita\",\n       caption=\"StatCan Tables 17-10-0020, 17-10-0040, 17-10-0009\")",
    "crumbs": [
      "Advanced descriptive analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>BC migration</span>"
    ]
  },
  {
    "objectID": "advanced_descriptive/advanced_descriptive_bc_migration.html#interpretation",
    "href": "advanced_descriptive/advanced_descriptive_bc_migration.html#interpretation",
    "title": "\n14  BC migration\n",
    "section": "\n14.6 Interpretation",
    "text": "14.6 Interpretation\nThis answers our question, the Q4 2021 year over year net migration edges over the 100,000 people mark, and in absolute terms this is the highest it’s been over at least 60 years. (And it climbed even higher in the following quarters.) And B.C.’s interprovincial (gross) in-migration was the highest in Canada in absolute terms. But what can we learn from that?\nB.C. 60 years ago is very different from B.C. today. To account for that we can normalize by population, and the relative net migration has been higher at several times during the past 60 years, most recently in the 90s.\nViewed relative to population size we note that other provinces, in particular some of the Atlantic Provinces, vastly outperform BC’s interprovincial net as well as gross in-migration in that timeframe, mostly fuelled by the 50k people that left Ontario during that time period.\nWe also note the big dip in net-migration during COVID-19. It is not clear if the current heights are a bounce-back to make up for the comparatively low net in-migration during the pandemic, or if it is simply reverting back to the increasing trend we have seen over the past 10 years.",
    "crumbs": [
      "Advanced descriptive analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>BC migration</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“VancouvR: Access the ’City of Vancouver’ Open Data API.”\n2019. The R Foundation. https://doi.org/10.32614/cran.package.vancouvr.\n\n\nvon Bergmann, Jens. 2021. Tongfen: R Package to Make Data Based on\nDifferent Geographies Comparable. https://mountainmath.github.io/tongfen/.\n\n\n———. 2022. Cmhc: R Package to Access, Retrieve, and Work with CMHC\nData. https://mountainmath.github.io/cmhc/.\n\n\nvon Bergmann, Jens, and Dmitry Shkolnik. 2021. Cansim: Functions and\nConvenience Tools for Accessing Statistics Canada Data Tables. https://mountainmath.github.io/cansim/.\n\n\nvon Bergmann, Jens, Dmitry Shkolnik, and Aaron Jacobs. 2022.\nCancensus: R Package to Access, Retrieve, and Work with Canadian\nCensus Data and Geography. https://mountainmath.github.io/cancensus/.",
    "crumbs": [
      "References"
    ]
  }
]